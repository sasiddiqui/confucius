"""<p>What does ""backprop"" mean? I've Googled it, but it's showing backpropagation.</p><br><br><p>Is the ""backprop"" term basically the same as ""backpropagation"" or does it have a different meaning?</p><br>""",ai
"""<p>Does increasing the noise in data help to improve the learning ability of a network? Does it make any difference or does it depend on the problem being solved? How is it affect the generalization process overall?</p><br>""",ai
"""<p>When you're writing your algorithm, how do you know how many neurons you need per single layer? Are there any methods for finding the optimal number of them, or is it a rule of thumb?</p><br>""",ai
"""<p>I have a LEGO Mindstorms EV3 and I'm wondering if there's any way I could start coding the bot in Python rather than the default drag-and-drop system. Is a Mindstorm considered AI?</p><br><br><p>Is this possible?</p><br><br><hr><br><br><p>My goal is to write a basic walking program in Python. The bot is the EV3RSTORM. I searched and found <a href=""http://bitsandbricks.no/2014/01/19/getting-started-with-python-on-ev3/"" rel=""nofollow"">this</a>, but don't understand it. </p><br>""",ai
"""<p>The intelligent agent definition of intelligence states that an agent is intelligent if it acts so to maximize the expected value of a performance measure based on past experience and knowledge. (paraphrased from <a href=""http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence#Intelligent_agent_definition"" rel=""nofollow"">Wikipedia</a>)</p><br><br><p>Does this mean that humans are not intelligent? I think we all make mistakes that imply that we are not maximizing the expected value of a performance measure.</p><br>""",ai
"""<p>This quote by Stephen Hawking has been in headlines for quite some time:</p><br><br><blockquote><br>  <p>Artificial Intelligence could wipe out humanity when it gets too clever as humans will be like ants.</p><br></blockquote><br><br><p>Why does he say this? To put it simply in layman terms: what are the possible threats from AI? If we know that AI is so dangerous why are we still promoting it? Why is it not banned?</p><br><br><p>What are the adverse consequences of the so called <a href=""https://en.wikipedia.org/wiki/Technological_singularity"" rel=""nofollow"">Technological Singularity</a>? </p><br>""",ai
"""<p>I'm new to A.I. and I'd like to know in simple words, what is the fuzzy logic concept? How does it help, and when is it used?</p><br>""",ai
"""<p>The <a href=""https://en.wikipedia.org/wiki/Turing_test"">Turing Test</a> was the first test of artificial intelligence and is now a bit outdated. The <a href=""https://en.wikipedia.org/wiki/Turing_test#Total_Turing_test"">Total Turing Test</a> aims to be a more modern test which requires a much more sophisticated system. What techniques can we use to identify an artificial intelligence (weak AI) and an <a href=""https://en.wikipedia.org/wiki/Artificial_general_intelligence"">artificial general intelligence</a> (strong AI)?</p><br>""",ai
"""<p>What is the ""early stopping"" and what are the advantages using this method? How does it help exactly.</p><br>""",ai
"""<p>I've heard the idea of the technological singularity, what is it and how does it relate to Artificial Intelligence?  Is this the theoretical point where Artificial Intelligence machines have progressed to the point where they grow and learn on their own beyond what humans can do and their growth takes off?  How would we know when we reach this point?</p><br>""",ai
"""<p>I'm worry that my network become too complex. I don't want to end up with half of the network does nothing, but just take space and resources.</p><br><br><p>So, what are the techniques of detecting and preventing overfitting to avoid such problem?</p><br>""",ai
"""<p>I've seen emotional intelligence defined as the capacity to be aware of, control, and express one's emotions, and to handle interpersonal relationships judiciously and empathetically.  What are some strategies for artificial intelligence to begin to tackle this problem and develop emotional intelligence for computers?  Are there examples where this is already happening to a degree today?  For example, wouldn't a computer that passes a Turing test necessarily express emotional intelligence or it would be seen as an obvious computer?  Perhaps that is why early programs that pass the test represented young people, who presumably have lower emotional intelligence.</p><br>""",ai
"""<p>Since human intelligence presumably is a function of a natural genetic algorithm in nature, is using a genetic algorithm in a computer an example of artificial intelligence?  If not, how do they differ?  Or perhaps some are and some are not expressing artificial intelligence depending upon the scale of the algorithm and what it evolves into?</p><br>""",ai
"""<p>These two terms seem to be related, especially in their application in computer science and software engineering.  Is one a subset of another?  Is one a tool used to build a system for the other?  What are their differences and why are they significant?</p><br>""",ai
"""<p>What aspects of quantum computers, if any, can help to further develop Artificial Intelligence?</p><br>""",ai
"""<p>I believe a Markov chain is a sequence of events where each subsequent event depends probabilistically on the current event.  What are examples of the application of a Markov chain and can it be used to create artificial intelligence?  Would a genetic algorithm be an example of a Markov chain since each generation depends upon the state of the prior generation?</p><br>""",ai
"""<p>What purpose does the ""dropout"" method serve and how does it improve the overall performance of the neural network?</p><br>""",ai
"""<p>Can an AI program have an IQ?</p><br><br><p>In other words, can the IQ of an AI program be measured?</p><br><br><p>Like how humans can do an IQ test.</p><br>""",ai
"""<p>Why anybody would want to use the ""hidden layers""? How they enhance the learning ability of the network in comparison to the network which doesn't have them (linear models)?</p><br>""",ai
"""<p>When did research into Artificial Intelligence first begin?  Was it called Artificial Intelligence then or was there another name?</p><br>""",ai
"""<p>How would you estimate the generalisation error? What are the methods of achieving this?</p><br>""",ai
"""<p>I've implemented <a href=""https://en.wikipedia.org/wiki/Reinforcement_learning"" rel=""nofollow"">the reinforcement learning alogrithm</a> for an agent to play <a href=""https://github.com/admonkey/snappybird"" rel=""nofollow"">snappy bird</a> (a shameless cheap ripoff of flappy bird) utilizing a q-table for storing the history for future lookups. It works and eventually achieves perfect convergence after enough training.</p><br><br><p>Is it possible to implement a neural network to do function approximation in order to accomplish the purpose of the q-table? Obviously storage is a concern with the q-table, but it doesn't seem to ever train with the neural net alone. Perhaps training the nnet on an existing q-table would work, but I would like to not use a q-table at all if possible.</p><br>""",ai
"""<p>I read that in the spring of 2016 a computer <a href=""https://en.wikipedia.org/wiki/Computer_Go"" rel=""nofollow"">Go program</a> was finally able to beat a professional human for the first time.  Now that this milestone has been reached, does that represent a significant advance in artificial intelligence techniques or was it just a matter of even more processing power being applied to the problem?  What are some of the methods used to program the successful Go playing program, and are those methods considered to be artificial intelligence?</p><br>""",ai
"""<p>Who first coined the term Artificial Intelligence, is there a published research paper which is the first to use that term?</p><br>""",ai
"""<p>I've read that the most of the problems can be solved with 1-2 hidden layers.</p><br><br><p>How do you know you need more than 2? For what kind of problems you would need them (as example)?</p><br>""",ai
"""<p>What were the first areas of research into Artificial Intelligence and what were some early successes?  More recently we've had:</p><br><br><ol><br><li>Beating a human at the game of chess</li><br><li>Convincing a human that a person was conversing with them (passing the Turing test)</li><br><li>Beating a human at Jeopardy game show</li><br><li>Beating a human at the game of go.</li><br></ol><br><br><p>Were there milestones that were considered major in the field before the 1990s?</p><br>""",ai
"""<p>Why somebody would use SAT solvers (<a href=""https://en.wikipedia.org/wiki/Boolean_satisfiability_problem"" rel=""nofollow"">Boolean satisfiability problem</a>) to solve their real world problems?</p><br><br><p>Are there any examples of the real uses of this model?</p><br>""",ai
"""<p>What designs for genetic algorithms are there, if they are classified differently and/or have different names, that leverage models for epigenetics in evolution? What are the pros/cons of the designs? Are there vast insufficiencies or wide-open questions about their usefulness? </p><br>""",ai
"""<p>Can a Convolutional Neural Network be used for pattern recognition in a problem domain where there are no pre-existing images, say by representing abstract data graphically? Would that always be less efficient?</p><br><br><p><a href=""https://youtu.be/py5byOOHZM8?t=815"">This developer</a> says current development could go further but not if there's a limit outside image recognition. </p><br>""",ai
"""<p>I've heard the terms strong-AI and weak-AI used.  Are these well defined terms or subjective ones?  How are they generally defined?</p><br>""",ai
"""<p>As AI gains capabilities, and becomes more prevalent in society, our legal system will encounter questions it has not encountered before.  For example, if a self-driving car is involved in an accident while being controlled by the AI, who is at fault?  The ""driver"" (who's really just a passenger), the programmer(s) who made the AI, or the AI itself?</p><br><br><p>So, what's on the cutting edge in terms of these kinds of issues at the intersection of law and artificial intelligence?</p><br>""",ai
"""<p>I know that language of <strong><code>Lisp</code></strong> was used early on when working on artificial intelligence problems.  Is it still being used today for significant work?  If not, is there a new language that has taken its place as the most common one being used for work in AI today?</p><br>""",ai
"""<p>What are the specific requirements of the Turing Test?</p><br><br><ul><br><li>What requirements if any must the evaluator fulfill in order to be qualified to give the test?</li><br><li>Must there always be two participants to the conversation (one human and one computer) or can there be more</li><br><li>Are placebo tests (where there is not actually a computer involbed) allowed or encouraged?</li><br><li>Can there be multiple evaluators? If so does the decision need to be unanimous among all evaluators in order for the machine to have passed the test?</li><br></ul><br>""",ai
"""<p>I believe that statistical AI uses inductive thought processes.  For example, deducing a trend from a pattern.  What are some examples of successfully applying statistical AI to real world problems.</p><br>""",ai
"""<p>How do the basic components <a href=""https://en.wikipedia.org/wiki/Optimality_theory"" rel=""nofollow"">optimality theory</a> apply to artificial intelligence?</p><br><br><p>How is optimality theory related to neural network research?</p><br>""",ai
"""<p>Some programs do exhaustive searches for a solution while others do heuristic searches.  For example, in chess, the search for the best next move tends to be more exhaustive in nature whereas in go, the search for the best next move tends to be more heuristic in nature due to the much larger search space.</p><br><br><p>Is the technique of brute force exhaustive searching for a good answer considered to be AI or is it generally required that heuristic algorithms be used before being deemed AI?  If so, is the chess playing computer beating a human professional seen as a meaningful milestone?</p><br>""",ai
"""<p>How is a neural network having the ""deep"" adjective actually distinguished from other similar networks?</p><br>""",ai
"""<p>What is the effectiveness of pre-training of unsupervised deep learning?</p><br><br><p>Does unsupervised deep learning actually work?</p><br>""",ai
"""<p>Are search engines considered AI because of the way they analyze what you search for and remember it? Or how they send you ads of what you've searched for recently? Is this considered AI or just smart?</p><br>""",ai
"""<p>In a feedforward neural network the inputs are fed directly to the outputs via a series of <strong>weights</strong>.</p><br><br><p>What purpose do the weights serve and how are they significant in this neural network?</p><br>""",ai
"""<p>I'm pretty sure this a noob-y question, but what is Deep Network? As of now it is the most popular tag on AI. Is there a reason for this? </p><br><br><hr><br><br><p>Please note, I am not asking how to distinguish a deep network from a neural network, I am simply asking for the definition of deep network.</p><br>""",ai
"""<p>I believe that Classical AI uses deductive thought processes. For example, given as a set of constraints, deduce a conclusion.  What are some examples of successfully applying Classical AI to real world problems.</p><br>""",ai
"""<p>In <a href=""https://youtu.be/oSdPmxRCWws?t=30"">this video</a> an expert says, ""One way of thinking about what intelligence is [specifically with regard to artificial intelligence], is as an optimization process.""</p><br><br><p>Can intelligence always be thought of as an optimization process, and can artificial intelligence always be modeled as an optimization problem? What about pattern recognition? Or is he mischaracterizing?</p><br>""",ai
"""<p>What specific advantages of declarative languages make them more applicable to AI than imperative languages?  What can declarative languages do easily that other languages styles find difficult for this kind of problem?</p><br>""",ai
"""<p>In years past, GOFAI (Good Old Fashioned AI) was heavily based on ""rules"" and <a href=""https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence"" rel=""nofollow"">symbolic computation</a> based on rules.  Unfortunately, that approach ran into stumbling blocks, and the world moved heavily towards statistical / probabilistic approaches leading to the current wave of interest in ""machine learning"".</p><br><br><p>It seems though, that the symbolic / rule based approach probably still has application. So, could one ""learn"" rules using a probabilistic <a href=""https://en.wikipedia.org/wiki/Rule_induction"" rel=""nofollow"">rule induction</a> method, and then layer symbolic computation on top?  If so, how could the whole process be made truly two-way, so that something ""learned"" from processing rules, can be fed back into how the system learns rules? </p><br>""",ai
"""<p>Which deep neural network is used in <a href=""https://en.wikipedia.org/wiki/Google_self-driving_car"" rel=""nofollow"">Google's driverless cars</a> to analyse the surroundings? Is this information is open?</p><br>""",ai
"""<p>Two common activation functions used in deep learning are the hyperbolic tangent function and the sigmoid activation function. I understand that the hyperbolic tangent is just a rescaling and translation of the sigmoid function (i,e tanh(z) = 2*sigma(z) - 1). </p><br><br><p>Is there a significant difference between these two activation functions, and in particular, <strong>when is one preferable to the other</strong>?</p><br><br><p>I realize that in some cases (like when estimating probabilities) outputs in the range of [0,1] are more convenient than outputs that range from [-1,1]. I want to know if there are differences <strong>other than convenience</strong> which distinguish the two activation functions.</p><br>""",ai
"""<p><a href=""http://ai.stackexchange.com/questions/10/what-is-fuzzy-logic"">Fuzzy logic</a> is the logic where every statement can have any real truth value between 0 and 1.</p><br><br><p>How can fuzzy logic be used in creating AI? Is it useful for certain decision problems involving multiple inputs? Can you give an example of an AI that uses it?</p><br>""",ai
"""<p>In <a href=""http://users.ox.ac.uk/~jrlucas/Godel/mmg.html"" rel=""nofollow"">Minds, Machines and Gödel</a> (1959), J. R. Lucas shows that any human mathematician can not be represented by an algorithmic automaton (a Turing Machine, but any computer is equivalent to it by the Church-Turing thesis), using Gödel's incompleteness theorem. </p><br><br><p>As I understand it, he states that since the computer is an algorithm and hence a formal system, Gödel's incompleteness theorem applies. But a human mathematician also has to work in a formal axiom system to prove a theorem, so wouldn't it apply there as well? </p><br>""",ai
"""<p>Back in college, I had a Complexity Theory teacher who stated that artificial intelligence was a contradiction in terms. If it could be calculated mechanically, he argued, it wasn't intelligence.</p><br><br><p>This seems to be a variant of the Chinese Room argument. This argument is a metaphor, where  a person is put in a room full of Chinese books. This person doesn't understand a word of Chinese, but is slipped messages in Chinese under the door. The person has to use the books, which contain transformation rules, to answer these messages. The person can apply the transformation rules, but does not understand what (s)he is communicating.</p><br><br><p>Does the chinese room argument hold? Can we argue that artificial intelligence is merely clever algorithmics?</p><br>""",ai
"""<p>What are the main differences between <a href=""https://en.wikipedia.org/wiki/Boltzmann_machine"" rel=""nofollow"">Deep Boltzmann Machines</a> (DBM) recurrent neural network and <a href=""https://en.wikipedia.org/wiki/Deep_belief_network"" rel=""nofollow"">Deep Belief Network</a> (which is based on RBMs)?</p><br>""",ai
"""<p>An ultraintelligent machine is a machine that can surpass all intellectual activities by any human, and such machine is often used in science fiction as a machine that brings mankind to an end. </p><br><br><p>Any machine is executed using an algorithm. By the Church-Turing thesis, any algorithm that can be executed by a modern computer can be executed by a Turing Machine. However, a human can easily simulate a Turing Machine. Doesn't this mean that a machine can't surpass all intellectual activities, since we can also execute the algorithm?</p><br><br><p>This argument is most likely flawed, since my intuition tells me that  ultraintelligent machines are possible. However, it is not clear to me where the flaw is. Note that this is my own argument. </p><br>""",ai
"""<p>From Wikipedia:</p><br><br><blockquote><br>  <p>AIXI ['ai̯k͡siː] is a theoretical mathematical formalism for artificial general intelligence. It combines Solomonoff induction with sequential decision theory. AIXI was first proposed by Marcus Hutter in 2000[1] and the results below are proved in Hutter's 2005 book Universal Artificial Intelligence.[2]</p><br></blockquote><br><br><p>Albeit non-computable, approximations are possible, such as <em>AIXItl</em>. Finding approximations to AIXI could be an objective way for solving AI.</p><br><br><p>My question is: is <em>AIXI</em> really a big deal in artificial <em>general</em> intelligence research? Can it be thought as a central concept for the field? If so, why don't we have more publications on this subject (or maybe we have and I'm not aware of them)?</p><br>""",ai
"""<p>In what ways can connectionist artificial intelligence (neural networks) be integrated with <em>Good Old-Fashioned A.I.</em> (<em>GOFAI</em>)? For instance, how could deep neural networks be integrated with knowledge bases or logical inference? One such example seems to be the <a href=""http://wiki.opencog.org/w/DestinOpenCog"" rel=""nofollow"">OpenCog + Destin integration</a>.</p><br>""",ai
"""<p>It is proved that a recurrent neural net with rational weights can be a super-Turing machine. Can we achieve this in practice ?</p><br>""",ai
"""<p>Given the proven <a href=""https://en.wikipedia.org/wiki/Halting_problem"">halting problem</a> for <a href=""https://en.wikipedia.org/wiki/Turing_machine"">Turing machines</a>, can we infer limits on the ability of strong Artificial Intelligence?</p><br>""",ai
"""<p>By default using <a href=""https://en.wikipedia.org/wiki/DeepDream"" rel=""nofollow"">DeepDream</a> technique you can creating a dreamlike image out of two different images.</p><br><br><p>Is it possible to easily enhance this technique to generate one image out from three?</p><br>""",ai
"""<p>Can autoencoders be used for supervised learning <em>without adding an output layer</em>? Can we simply feed it with a concatenated input-output vector for training, and reconstruct the output part from the input part when doing inference? The output part would be treated as missing values during inference and some imputation would be applied.</p><br>""",ai
"""<p>From Wikipedia:</p><br><br><blockquote><br>  <p>A mirror neuron is a neuron that fires both when an animal acts and when the animal observes the same action performed by another.</p><br></blockquote><br><br><p>Mirror neurons are related to imitation learning, a very useful feature that is missing in current real-world A.I. implementations. Instead of learning from input-output examples (supervised learning) or from rewards (reinforcement learning), an agent with mirror neurons would be able to learn by simply observing other agents, translating their movements to its own coordinate system. What do we have on this subject regarding computational models?</p><br>""",ai
"""<p>If I have a paragraph I want to summarize, for example:</p><br><br><blockquote><br>  <p>Ponzo and Fila went to the mall during the day. They walked for a long while, stopping at shops. They went to many shops. At first, they didn't buy anything. After going to a number of shops, they eventually bought a shirt, and a pair of pants.</p><br></blockquote><br><br><p>Better summarized as:</p><br><br><blockquote><br>  <p>They shopped at the mall today and bought some clothes.</p><br></blockquote><br><br><p>What is the best AI strategy to automate this process, if there is one? If there isn't, is it because it would be dependent on first having an external information resource that would inform any algorithm? Or is it because the problem is inherently contextual?</p><br>""",ai
"""<p>What happens if you apply the same <a href=""https://en.wikipedia.org/wiki/DeepDream"" rel=""nofollow"">deep dream technique</a> which produces ""dream"" visuals, but to media streams such as audio files?</p><br><br><p>Does changing image functions into audio and enhancing the logic would work, or it won't work or doesn't make any sense?</p><br><br><p>My goal is to create ""dream"" like audio based on the two samples.</p><br>""",ai
"""<p>With which neural network it is possible to scale the learning between the independent networks?</p><br><br><p>For example given the stream of images one network is trained to recognise cats, another dogs, and so on, all of them are talking to the main visual network which is responsible for making some decision and pass the analysis to the main ""brain"" network. Then another network of neural network are given the audio so each network can recognise specific pattern, then they talk to the common audio specific network which talks to the main ""brain"" network (mentioned before). In other words, something like a robot.</p><br><br><p>Which type of network would be the most suitable and scalable for such configuration, so you can easily extend it for additional separate network modules? Does it matter which type of deep network (or not deep) I should choose, or not?</p><br>""",ai
"""<p>In <a href=""https://en.wikipedia.org/wiki/DeepDream"" rel=""nofollow"">DeepDream</a> wikipedia page it's suggested that a dreamlike images created by a convolutional neural network may be related to how visual cortex works in humans when they're tripping.</p><br><br><blockquote><br>  <p>The imagery to LSD- and psilocybin-induced hallucinations is suggestive of a functional resemblance between artificial neural networks and particular layers of the visual cortex.</p><br></blockquote><br><br><p>How this is even possible?</p><br><br><p>How exactly convolutional neural networks have anything to do with human visual cortex?</p><br>""",ai
"""<p>This 2014 <a href=""https://medium.com/the-physics-arxiv-blog/first-demonstration-of-artificial-intelligence-on-a-quantum-computer-17a6b9d1c5fb"" rel=""nofollow"">article</a> saying that a Chinese team of physicists have trained a quantum computer to recognise handwritten characters.</p><br><br><p><strong>Why did they have to use a quantum computer</strong> to do that?</p><br><br><p>Is it just for fun and demonstration, or is it that recognising the handwritten characters is so difficult that standard (non-quantum) computers or algorithms cannot do that?</p><br><br><p>If standard computers can achieve the same thing, what are the benefits of using quantum computers to do that then over standard methods?</p><br>""",ai
"""<p>Is it possible that at some time in the future, AIs will be able to initiatively develop themselves, rather than passively being developed by humanity?</p><br>""",ai
"""<p>Which is the preferred algorithm to build word vector for a given language?</p><br>""",ai
"""<p>How to decide the optimum number of layers to be created while implementing a Neural Network (Feedforward, back propagation or RNN)?</p><br>""",ai
"""<p>Have there been proposed extensions to go beyond a Turing machine that solve the halting problem and if so, would those proposed extensions have value to advance strong Artificial Intelligence?  For example, does quantum computing go beyond the definition of a Turing machine and resolve the halting problem, and does that help in creating strong AI?</p><br>""",ai
"""<p>What was the first AI that was able to carry on a conversation, with real responses, such as in the famous <a href=""https://www.youtube.com/watch?v=WnzlbyTZsQY"" rel=""nofollow"">'I am not a robot. I am a unicorn' case?</a></p><br><br><p>A 'real response' constitutes a sort-of personalized answer to a specific input by a user.</p><br>""",ai
"""<p>This question stems from quite a few ""informal"" sources. Movies like <em>2001, A Space Odyssey</em> and <em>Ex Machina</em>; books like <em>Destination Void</em> (Frank Herbert), and others suggest that general intelligence <em>wants</em> to survive, and even learn the importance for it.</p><br><br><p>There may be several arguments for survival. What would be the most prominent?</p><br>""",ai
"""<p>Identifying sarcasm is considered as one of the most difficult open-ended problems in the domain of ML and NLP.</p><br><br><p>So, was there any considerable research done in that front? If yes, then what is the accuracy like? Please also explain the NLP model briefly.</p><br>""",ai
"""<p>I'd like to know more about <a href=""http://ai.stackexchange.com/q/26/8"">implementing emotional intelligence</a>.</p><br><br><p>Given I'm implementing a chat bot and I'd like to introduce the levels of curiosity to measure whether user text input is interesting or not.</p><br><br><p>High level would mean bot is asking more questions and is following the topic, lower level of curiosity makes the bot not asking any questions and changing the topics.</p><br><br><p>Less interesting content could mean the bot doesn't see any opportunity to learn something new or it doesn't understand the topic or doesn't want to talk about it, because of its low quality. </p><br><br><p>How this possibly can be achieved? Are there any examples?</p><br>""",ai
"""<p>Text summarization is a long-standing research problem that was <em>""ignited""</em> by Luhn in 1958. However, a half century later, we still came nowhere close  to solving this problem (abstractive summarization). The reason for this might be because researchers are resorting to statistical (and sometimes linguistic) methods to find &amp; extract the most salient parts of the text.</p><br><br><p>Is summarization problem solvable using AI (neural networks to be precise)? </p><br>""",ai
"""<p>I'd like to know which common file format is more efficient in terms of simplicity and storage space for storing the state of artificial neural network.</p><br><br><p>I'm not talking about memory storage, but file storage, so the data can be loaded later on.</p><br><br><p>My first guess would be XML, but having millions of connections and weights would generate huge amount of data. Another thing would be to dump object instances into binary file using some export/serialize functions, but the disadvantage is that the file isn't common and it's language specific.</p><br><br><p>Are there any common file format standards which can be used for exporting huge artificial neural network into the file to be loaded by another program? If so, which one.</p><br>""",ai
"""<p>What AI techniques does IBM use for its Watson platform, specifically its natural language analysis?</p><br>""",ai
"""<p>I'm investigating the possibility of storing the semantic-lexical connections (such as the relationships to the other words such as phrases and other dependencies, its strength, part of speech, language, etc.) in order to provide analysis of the input text.</p><br><br><p>I assume this has been already done. If so, to avoid reinventing the wheel, is there any efficient method to store and manage such data in some common format which has been already researched and tested?</p><br>""",ai
"""<p>Which objective and measurable tests have been developed to test the intelligence of AI? </p><br><br><p>The classical test is the Turing Test, which has objective criteria and is measurable since it can be measured what percentage of the jury is fooled by the AI.</p><br><br><p>I am looking for other, more modern tests. </p><br>""",ai
"""<p>Unsupervised learning does not involve target values, so basically targets are most likely the same as the inputs (in other words, involves no target values).</p><br><br><p>So how does this model learn?</p><br>""",ai
"""<p>One of the most compelling applications for AI would be in augmenting human biological intelligence. What are some of the currently proposed methods for doing this aside from vague notions such as ""nanobots swimming around our brains and bodies"" or ""electrodes connected to our skulls""?</p><br>""",ai
"""<p>Given list of fixed numbers from a mathematical constant such as Pi, is it is possible to train AI to attempt to predict the next numbers?</p><br><br><p>Which AI or neural network would be more suitable for this task? </p><br><br><p>Especially the one which will work without memorizing the entire training set, but the one which will attempt to find some patterns or statistical association.</p><br>""",ai
"""<p>What are the main differences between two types of feedforward networks such as <em>multilayer perceptrons</em> (MLP) and <em>radial basis function</em> (RBF)?</p><br><br><p>What are the fundamental differences between these two types?</p><br>""",ai
"""<p>According to my knowledge most of the current artificial intelligence study uses of some kind of neural network or its variants. A good example would be DeepMind's alphago which I believe is a deep neural network, for vision CNN, text, music and other ordered features RNN's, etc. But for machine learning application we have neural networks, support vector machines, random forest, regression methods, etc. available for applications. </p><br><br><p>So are neural networks and its variants the only way to reach ""true"" artificial intelligence? </p><br>""",ai
"""<p>I'm interested in hardware implementation of ANNs (artificial neural networks). Are there any popular existing technology implementations in form of microchips which are purpose designed to run artificial neural networks? For example, a chip which is optimised for an application like image recognition or something similar?</p><br>""",ai
"""<p>I've noticed that a few questions on this site mention genetic algorithms and it made me realize that I don't really know much about those.</p><br><br><p>I have heard the term before, but it's not something I've ever used, so I don't have much idea about how they work and what they are good for. All I know is that they involve some sort of evolution and randomly changing values.</p><br><br><p>Can you give me a short explanation, preferably including some sort of practical example that illustrates the basic principles?</p><br>""",ai
"""<p>In detective novels, the point is often that the reader gets enough information to solve the crime themselves. This ""puzzle"" aspect of detective novels is part of the attraction.</p><br><br><p>Often the difficulty for humans is to keep track of all the variables - events, items, motivations.<br><br>An AI would have an easier time keeping track of all the details, but would rely on real-world knowledge to prevent making crazy mistakes. For example, if it was stated that a character took the train, the AI would need to know that this is a method of transportation - that it changes the location property of an agent over time.</p><br><br><p>Has an AI ever been able to solve a detective mystery?</p><br>""",ai
"""<p>In 1969, Seymour Papert and Marvin Minsky showed that Perceptrons could not learn the XOR function.  </p><br><br><p>This was solved by the backpropagation network with at least one hidden layer. This type of network can learn the XOR function.</p><br><br><p>I believe I was once taught that every problem that could be learnt by a backpropagation neural network with multiple hidden layers, could also be learnt by a backpropagation neural network with a single hidden layer. (Although possible a nonlinear activation function was required).</p><br><br><p>However, it is unclear to me what the limits are to backpropagation neural networks themselves. Which patterns <strong>cannot</strong> be learnt by a backpropgation neural network?</p><br>""",ai
"""<p>Over the last 50 years, the rise/fall/rise in popularity of neural nets has acted as something of a 'barometer' for AI research.</p><br><br><p>It's clear from the questions on this site that people are interested in applying Deep Learning (DL) to a wide variety of difficult problems.</p><br><br><p>I therefore have two questions:</p><br><br><ol><br><li>Practitioners - What do you find to be the main obstacles to<br>applying DL 'out of the box' to your problem? </li><br><li>Researchers - What<br>techniques do you use (or have developed) that might help address<br>practical issues? Are they within DL or do they offer an<br>alternative approach?</li><br></ol><br>""",ai
"""<p>Is it possible for <em>unsupervised learning</em> to learn about high-level, class-specific features given only unlabelled images? For example detecting human or animal faces? If so, how?</p><br>""",ai
"""<p>On the Wikipedia page we can read the basic structure of an artificial neuron (a model of biological neurons) which consist:</p><br><br><ul><br><li>Dendrites - acts as the input vector,</li><br><li>Soma - acts as the summation function,</li><br><li>Axon - gets its signal from the summation behavior which occurs inside the soma.</li><br></ul><br><br><p>I've checked <a href=""https://en.wikipedia.org/wiki/Deep_learning"" rel=""nofollow"">Deep learning</a> wiki page, but I couldn't find any references to dendrites, soma or axons.</p><br><br><p>So my question is, which type of artificial neural network implements or can mimic such model most closely?</p><br>""",ai
"""<p>Have there been any studies which attempted to use AI algorithms to detect human thoughts or emotions based on brain activity, such as using <a href=""https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface#EEG-based"" rel=""nofollow"">BCI/EEG devices</a>?</p><br><br><p>By this, I mean simple guesses such as whether the person was happy or angry, or what object (e.g. banana, car) they were thinking about.</p><br><br><p>If so, did any of those studies show some degree of success?</p><br>""",ai
"""<p>Has there been any attempts to deploy AI with blockchain technology? </p><br><br><p>Are there any decentralized examples of AI networks with no central point of control with AI nodes acting independently (but according to a codified set of rules) creating, validating and storing the same shared decentralized database in many locations around the world?</p><br>""",ai
"""<p>In their famous book entitled ""<em>Perceptrons: An Introduction to Computational Geometry</em>"", Minsky and Papert show that a perceptron can't solve the XOR problem. This contributed to the first AI winter, resulting in funding cuts for neural networks. However, now we know that a multilayer perceptron can solve the XOR problem easily.</p><br><br><p>Backprop wasn't known at the time, but did they know about manually building multilayer perceptrons? Did Minsky &amp; Papert know that multilayer perceptrons could solve XOR at the time they wrote the book, albeit not knowing how to train it?</p><br>""",ai
"""<p>Deep Mind has published a lot of works on deep learning in the last years, most of them state-of-the-art on their respective tasks. But how much of this work has actually been reproduced by the AI community? For instance, the Neural Turing Machine paper seems to be very hard to reproduce, according to other researchers.</p><br>""",ai
"""<p>Geoffrey Hinton has been researching something he calls ""capsules theory"" in neural networks. What is this and how does it work?</p><br>""",ai
"""<p>During my research, I've stumbled upon ""complex-valued neural networks"", which are neural networks that work with complex-valued inputs (probably weights too). What are the advantages (or simply the applications) of this kind of neural network over real-valued neural networks?</p><br>""",ai
"""<p>The <a href=""http://fabelier.org/novelty-search-and-open-ended-evolution-by-ken-stanley/"" rel=""nofollow"">author</a> claims that guiding evolution by novelty alone (without explicit goals) can solve problems even better than using explicit goals. In other words, using a novelty measure as a fitness function for a genetic algorithm works better than a goal-directed fitness function. How is that possible?</p><br>""",ai
"""<p>Quote from this <a href=""http://meta.ai.stackexchange.com/a/46/8"">Eric's meta post</a> about modelling and implementation:</p><br><br><blockquote><br>  <p>They are not exactly the same, although strongly related. This was a very difficult lesson to learn among mathematicians and early programmers, notably in the 70s (mathematical proofs can demand a lot of non-trivial programming work to make them ""computable"", as in runnable on a computer).</p><br></blockquote><br><br><p>If they're not the same, what is the difference?</p><br><br><p>How we can say when we're talking about AI implementation, and when about modelling? It's suggested above it's not easy task. So where we can draw the line when we talk about it?</p><br><br><p>I'm asking in general, not specifically for this site, that's why I haven't posted question in meta</p><br>""",ai
"""<p>Given pictures with multiple features such as faces, can single AI algorithm detect all of them, or for better reliability is it preferred to use separate instances?</p><br><br><p>In other words I'm talking about attempt of finding all possible human faces on the same picture by a single neural network.</p><br>""",ai
"""<p>I read some information<sup>1</sup> about attempts to build neural networks in the PHP programming language. Personally I think PHP is not the right language to do so at all probably because it's a high-level language, I assume low level language are way more suitable for AI in terms of performance and scalability. </p><br><br><p>Is there a good/logical reason why you should or shouldn't use PHP as a language to write AI in?</p><br><br><p><em><sup>1</sup></em> <a href=""http://www.developer.com/lang/php/creating-neural-networks-in-php.html"" rel=""nofollow"">http://www.developer.com/lang/php/creating-neural-networks-in-php.html</a> and <a href=""http://stackoverflow.com/questions/2303357/are-there-any-artificial-intelligence-projects-in-php-out-there"">http://stackoverflow.com/questions/2303357/are-there-any-artificial-intelligence-projects-in-php-out-there</a> </p><br>""",ai
"""<p>I've found <a href=""http://link.springer.com/chapter/10.1007%2F978-1-4613-1009-9_2"" rel=""nofollow"">this old scientific paper from 1988</a> about introduction of AI into nuclear power fields.</p><br><br><p>Were or still are there any dangers by application of such algorithm? Are nuclear power plants or human life in risk if the algorithm will fail?</p><br><br><p>Especially applications to the core, like cooling systems and other components which can be affected in negative way.</p><br>""",ai
"""<p>How likely AI can fully replace pilots on commercial flights (including take off, landing and parking)?</p><br><br><p>Since we've self-driving cars already, is it likely to happen to commercial planes as well?</p><br>""",ai
"""<p>How much processing power is needed to emulate the human brain? More specifically, the neural simulation, such as communication between the neurons and processing certain data in real-time.</p><br><br><p>I understand that this may be a bit of speculation and it's not possible to be accurate, but I'm sure there is some data available or research studies which attempted to estimate it based on our current understanding of the human brain.</p><br>""",ai
"""<p>Artificial intelligence is present in many games, both current and older games. How can such intelligence understand what to do? I mean, how can it behave like a human in a game, allowing you to play against itself, or that AI plays against itself?</p><br><br><p>In games like Age of Empires, for example.</p><br>""",ai
"""<p><a href=""http://cs.stackexchange.com/a/60535/54605"">At a related question in Computer Science SE</a>, a user told:</p><br><br><blockquote><br>  <p>Neural networks typically require a large training set.</p><br></blockquote><br><br><p>Is there a way to define the boundaries of the ""optimal"" size of a training set in general case?</p><br><br><p>When I was learning about fuzzy logic, I've heard some rules of thumb that involved examining the mathematical composition of the problem and using that to define the number of fuzzy sets.</p><br><br><p>Is there such a method that can be applicable for an already defined neural network topology? </p><br>""",ai
"""<p>How important is true (non-<a href=""https://en.wikipedia.org/wiki/Pseudorandomness"" rel=""nofollow"" title=""pseudo"">pseudo</a>) randomness in Artificial Intelligence designs? Is there any chance that pseudo-randomness could be a barrier to more successful designs?</p><br>""",ai
"""<p>Complex AI that learns lexical-semantic content and its meaning (such as collection of words, their structure and dependencies) such as <em>Watson</em> takes terabytes of disk space.</p><br><br><p>Lets assume <em>DeepQA</em>-like AI consumed whole Wikipedia of size 10G which took the same amount of structured and unstructured stored content.</p><br><br><p>Will learning another 10G of different encyclopedia (different topics in the same language) take the same amount of data? Or will the AI reuse the existing structured and take less than half (like 1/10 of it) additional space?</p><br>""",ai
"""<p>Is there any simple explanation how <em>Watson</em> finds and scores evidence after gathering massive evidence and analyzing the data?</p><br><br><p>In other words, how does it know which precise answer it needs to return?</p><br>""",ai
"""<p>Are there any modern techniques of generating <strong>textual</strong> CAPTCHA (so person needs to type the right text) challenges which can easily <a href=""http://ai.stackexchange.com/q/92/8"">fool AI</a> with some visual obfuscation methods, but at the same time human can solve them without any struggle?</p><br><br><p>For example I'm talking about plain ability of <strong>recognising text embedded into image</strong> (without considering any external plugins like flash or java, image classification, etc.) and re-typing the text that has been written or something similar.</p><br><br><p>I guess adding noise, gradient, rotating letters or changing colours are not reliable methods any more, since they can be quickly broken.</p><br><br><p>Any suggestions or research has been done?</p><br>""",ai
"""<p>Can an AI program have an EQ (Emotional intelligence or emotional quotient)?</p><br><br><p>In other words, can the EQ of an AI program be measured?</p><br><br><p>If EQ is more problematic to measure than IQ (at least with a standard applicaple to both humans and AI programs), why is that the case?</p><br>""",ai
"""<p>I have heard about this concept in a reddit post about Alpha Go. I have trued to go through the paper and the article, but could not really make sense of the algorithm.</p><br><br><p>So, can someone give a easy-to-understand explanation of how the Monte-Carlo search algorithm work and how is it being used in building game-playing AI bots?</p><br>""",ai
"""<p>DNNs are typically used to classify things (of course) but can we let them go wild with sounds and then tell them if we think it sounds good or not? I'd like to think after a training class has been made (perhaps comparing the output to an existing song) we could get an NN that has a basic concept of music.</p><br><br><p>Timing would be an issue; I'm not sure how feasible this is. A strongly weighted input attached to all hidden layers perhaps? Use it as the bias?</p><br><br><p>Is this even slightly feasible? </p><br>""",ai
"""<p>How do I avoid my gradient descent algorithm into falling into the ""local minima"" trap while backpropogating on my neural network?</p><br><br><p>Are there any methods which help me avoid it?</p><br>""",ai
"""<p>A neural network is a directed weighted graph. These can be represented by a (sparse) matrix. Doing so can expose some elegant properties of the network.</p><br><br><p>Is this technique beneficial for examining neural networks?</p><br>""",ai
"""<p>Would it be ethical to implement AI for self-defence for public walking robots which are exposed to dangers such as violence and crime such as robbery (of parts), damage or abduction?</p><br><br><p>What would be pros and cons of such AI behavior? Is it realistic, or it won't be taken into account for some obvious reasons?</p><br><br><p>Like pushing back somebody when somebody start pushing it first (AI will say: he pushed me first), or running away on crowded street in case algorithm will detect risk of abduction.</p><br>""",ai
"""<p>Is there any risk in the near future of replacing all encyclopedias with Watson-like AI where knowledge is accessible by everybody through <a href=""https://watson-api-explorer.mybluemix.net/"" rel=""nofollow"">API</a>?</p><br><br><p><sup>Something similar happened in the future in <a href=""https://en.wikipedia.org/wiki/The_Time_Machine_(2002_film)"" rel=""nofollow""><strong>The Time Machine</strong> movie from 2002</a>.</sup></p><br><br><p>Obviously maintaining 40 million articles and keeping it up-to-date and consistent could be beyond brain power of few thousands of active editors. Not to mention thousands of other encyclopedias including paperback version or large number of books used by universities which needs to be updated every year by a huge number of people.</p><br><br><p>What are the pros and cons of such a change?</p><br>""",ai
"""<p>I've watched the <a href=""https://www.youtube.com/watch?v=LY7x2Ihqjmc"" rel=""nofollow"">Sunspring</a> video which didn't make any sense to me (a lot of nonsense monologues), mainly because it was created by Jetson AI.</p><br><br><p>What was the mechanism of creating such screenplay?</p><br><br><p>On what criteria was it trained? What was the goal or motivation in terms of training criteria of defining when text does make sense? And what was missed (that it's so bad) and how possibly this could be improved?</p><br>""",ai
"""<p>Is there any research which study application of AI into chemistry which can predict the output of certain chemical reactions.</p><br><br><p>So for example, you train the AI about current compounds, substances, structures and their products and chemical reactions from the existing <a href=""http://opendata.stackexchange.com/q/3553/3082"">dataset</a> (basically what produce what). Then you give the task to find how to create a gold or silver from group of available substances. Then the algorithm will find the chemical reactions (successfully predicting new one which weren't in the dataset) and gives the results. Maybe the gold is not a good example, but the practical scenario would be creation of drugs which are cheaper to create by using much more simpler processes or synthesizing some substances for the first time for drug industries.</p><br><br><p>Was there any successful research attempting to achieve that using deep learning algorithms?</p><br>""",ai
"""<p>Assume that I want to solve an issue with neural network that either I can't fit to already existing topologies (perceptron, Konohen, etc) or I'm simply not aware of the existence of those or I'm unable to understand their mechanics and I rely on my own instead.</p><br><br><p>How can I deconstruct a problem to find a corresponding neural network topology? By this I don't mean only the size of certain layers, but the number of them, the type of activation functions, the number and the direction of connections, and so on.</p><br><br><p>I'm a beginner, yet I realized that in some topologies (or, at least in perceptrons) it is very hard if not impossible to understand the inner mechanics as the neurons of the hidden layers don't express any mathematically meaningful context.</p><br>""",ai
"""<p>For example there is <a href=""https://en.wikipedia.org/wiki/MNIST_database"" rel=""nofollow"">the MNIST database</a> which is used to test artificial neural network (ANN), however it's not so challenging, because some hierarchical systems of convolutional neural networks manages to get an error rate of 0.23 percent.</p><br><br><p>Are there any similar, especially the most challenging tasks with dataset which are used as benchmark tests to challenge the AI which are fairly reliable and it's possible to pass, but most AAN are struggling to achieve the lower error rate?</p><br>""",ai
"""<p>This <a href=""http://repository.supsi.ch/5145/1/IDSIA-04-12.pdf"" rel=""nofollow"">study</a> (pages 7-8) shows an attempt at recognizing the traffic signs with lower error rates by using multi-column deep neural networks </p><br><br><p>Are Google cars using similar techniques of predicting signs using DNN, or are they using some other method?</p><br>""",ai
"""<p>I'd like to know whether there were attempts to simulate the whole brain, I'm not talking only about some <a href=""http://ai.stackexchange.com/q/237/8"">ANN on microchips</a>, but brain simulations.</p><br>""",ai
"""<p>On <a href=""https://en.wikipedia.org/wiki/Artificial_intelligence"">the wikipedia page</a> about AI, we can read:</p><br><br><blockquote><br>  <p>Optical character recognition is no longer perceived as an exemplar of ""artificial intelligence"" having become a routine technology.</p><br></blockquote><br><br><p>On the other hand, the <a href=""https://en.wikipedia.org/wiki/MNIST_database"">MNIST</a> database of handwritten digits is especially designed for training and testing neural networks and their error rates (see: <a href=""https://en.wikipedia.org/wiki/MNIST_database#Classifiers"">Classifiers</a>).</p><br><br><p>So why does the above quote state that OCR is no longer exemplar of AI?</p><br>""",ai
"""<p><a href=""https://en.wikipedia.org/wiki/Minimum_intelligent_signal_test"" rel=""nofollow"">MIST</a> is a quantiative test of humanness, consisting of ~80k propositions such as:</p><br><br><ul><br><li>Is Earth a planet?</li><br><li>Is the sun bigger than my foot?</li><br><li>Do people sometimes lie?</li><br><li>etc.</li><br></ul><br><br><p>Have any AI attempted and passed this test to date?</p><br>""",ai
"""<p>It is possible of normal code to prove that it is correct using mathematical techniques, and that is often done to ensure that some parts are bug-free. </p><br><br><p>Can we also prove that a piece of code in AI software will cause it to never turn against us, i.e. that the AI is <a href=""https://en.wikipedia.org/wiki/Friendly_artificial_intelligence"" rel=""nofollow"">friendly</a>? Has there any research been done towards this?</p><br>""",ai
"""<p>In <a href=""http://arxiv.org/pdf/1606.00652.pdf"" rel=""nofollow"">this paper</a>, a proposal is given for what death could mean for Artificial Intelligence. </p><br><br><p>What does this mean using English only? I understand that mathematical notation is useful for giving a precise definition, but I'd like to understand what the definition really means. </p><br>""",ai
"""<p>We can measure the power of the machine with the number of operation per second or the frequency of the processor. But does units similar of IQ for humans exist for a AI?<br/><br>I'm asking for a unit which can give countable result so something different from a Turing Test which only give a binary result.</p><br>""",ai
"""<p>In the mid 1980s, Rodney Brooks famously created the foundations of ""the new AI"". The central claim was that the symbolist approach of 'Good Old Fashioned AI' (GOFAI) had failed by attempting to 'cream cognition off the top', and that <em>embodied cognition</em> was required, i.e. built from the bottom up in a 'hierarchy of competances' (e.g. basic locomotion -> wandering around -> actively foraging) etc.</p><br><br><p>I imagine most AI researchers would agree that the 'embodied cognition' perspective has now (at least tacitly) supplanted GOFAI as the mainstream.</p><br><br><p>My question takes the form of a thought experiment and asks: ""Which (if any)  aspects of 'embodied' can be relaxed/omitted before we lose something essential for AGI?""</p><br>""",ai
"""<p>In other words, which existing reinforcement method learns in fewest episodes? <a href=""http://www.jmlr.org/papers/volume3/brafman02a/brafman02a.pdf"" rel=""nofollow"">R-Max</a> comes to mind, but its very old and I'd like to know if there is something better now.</p><br>""",ai
"""<p>Are there any research teams which attempted to create or have already created an AI robot which can be as close to intelligent as these found in <a href=""https://en.wikipedia.org/wiki/Ex_Machina_(film)""><em>Ex Machina</a></em> or <em><a href=""https://en.wikipedia.org/wiki/I,_Robot_(film)"">I, Robot</em></a> movies?</p><br><br><p>I'm not talking about full awareness, but an artificial being which can make its own decisions and physical and intellectual tasks that a human being can do?</p><br>""",ai
"""<p>We, humans, during following multiple processes (e.g. reading while listening to music) memorize information from less focused sources with worse efficiency than we do from our main concentration.</p><br><br><p>Do such things exist in case of artificial intelligences? I doubt, for example that neural networks obtain such features, but I may be wrong.</p><br>""",ai
"""<p>How can a swarm of small robots (like Kilobots) walking close to each other achieve collaboration without bumping into each other? For example, one study shows <a href=""http://science.sciencemag.org/content/345/6198/795.abstract"" rel=""nofollow"">programmable self-assembly in a thousand-robot swarm</a> (see <a href=""http://robohub.org/thousand-robot-swarm-self-assembles-into-arbitrary-shapes/"" rel=""nofollow"">article</a> &amp; <a href=""https://vimeo.com/103329200"" rel=""nofollow"">video</a>) which are moving without GPS-like system and by measuring distances to neighbours. This was achieved, because the robots were very slow.</p><br><br><p>Is there any way that similar robots can achieve much more efficient and quicker assembly by using more complex techniques of coordination? Not by walking around clock-wise (which I guess was the easiest way), but I mean using some more sophisticated way. Because waiting half a day (~11h) to create a simple star shape using a thousand-robot swarm is way too long!</p><br>""",ai
"""<p>On Watson wiki page we can read:</p><br><br><blockquote><br>  <p>In healthcare, Watson's natural language, hypothesis generation, and evidence-based learning capabilities allow it to function as a clinical decision support system for use by medical professionals.</p><br></blockquote><br><br><p>How exactly such AI can help doctors to diagnose the diseases?</p><br>""",ai
"""<p>Recently White House published the article: <a href=""https://www.whitehouse.gov/blog/2016/05/03/preparing-future-artificial-intelligence"" rel=""nofollow"">Preparing for the Future of Artificial Intelligence</a> which says that government is working to leverage AI for public good and toward a more effective government.</p><br><br><p>I'm especially interested how AI can help with computational sustainability, environmental management and Earth's ecosystem such as biological conservation?</p><br>""",ai
"""<p>When AI has some narrow domain such as chess where it can outperform the world's human masters of chess, does it make it a superintelligence or not?</p><br>""",ai
"""<p>Suppose my goal is to collaborate and create an advanced AI, for instance one that resembles a human being and the project would be on the frontier of AI research, what kind of skills would I need?</p><br><br><p>I am talking about specific things like what university program should I complete to enter and be competent in the field. Here are some of the things that I thought about, just to exemplify what I mean:</p><br><br><ul><br><li>Computer sciences: obviously the AI is built on computers, it wouldn't hurt to know how computers work, but some low level stuff and machine specific things does not seem essential, I may be wrong of course.</li><br><li>Psychology: if AI resembles human beings, knowledge of human cognition would probably be useful, although I do not imagine neurology on a cellular level or complicated psychological quirks typical to human beings like the Oedipus complex would be relevant, but again, I may be wrong.</li><br></ul><br>""",ai
"""<p><a href=""https://www.whitehouse.gov/webform/rfi-preparing-future-artificial-intelligence"" rel=""nofollow"">White House published the information</a> about AI which requests mentions about 'the most important research gaps in AI that must be addressed to advance this field and benefit the public'.</p><br><br><p>What are these exactly?</p><br>""",ai
"""<p>Is there any methods by which artificial intelligence use recursion(s) to solve a certain issue or to keep up working and calculating?</p><br>""",ai
"""<p>Convolutional neural network are leading type of feed-forward artificial neural network for image recognition. Can they be used for real-time image recognition for videos (frame by frame), or it takes too much processing (assuming they're written in C-like language)?</p><br><br><p>For example for classification of type of animals based on the training from huge dataset.</p><br>""",ai
"""<p>Just for the purpose of learning I'd like to classify the likeliness of a tweet being in aggressive language or not. </p><br><br><p>I was wondering how to approach the problem. I guess I need first train my neural network on a huge dataset of text what aggressive language is. This brings up the question where I would get this data in the first place?</p><br><br><p>It feels a bit like the chicken and egg problem to me so I wonder how would I approach the problem?</p><br>""",ai
"""<p>Siri and Cortana communicate pretty much like humans. Unlike Google now which mainly gives us search results when asked some questions (not setting alarms or reminders), Siri and Cortana provide us with an answer, in the same way that a person would do.<br><br>So are they actual AI programs or not?</p><br><br><p>(By ""question"" I don't mean any academic related question or asking routes/ temperature, but rather opinion based question). </p><br>""",ai
"""<p>The question is pretty much the title.</p><br><br><p>Basically what is the difference between AI and robots?</p><br>""",ai
"""<p>With typical machine learning you would usually use a training data-set to create a model of some kind, and a testing data-set to then test the newly created model. For something like linear regression after the model is created with the training data you now have an equation that you would use to predict the outcome of the set of features in the testing data. You would then take the prediction that the model returned and compare that to the actual data in the testing set. How would a validation set be used here?</p><br><br><p>With nearest neighbor you would use the training data to create an n-dimensional space that has all the features of the training set. You would then use this space to classify the features in the testing data. Again you would compare these predictions to the actual value of the data. How would a validation set help here as well?</p><br>""",ai
"""<p>By reinforcement learning, I don't mean the class of machine learning algorithms such as DeepQ, etc. I have in mind the general concept of learning based on rewards and punishment. </p><br><br><p>Is it possible to create a Strong AI that does not rely on learning by reinforcement, or is reinforcement learning a requirement for artificial intelligence? The existence of rewards and punishment imply the existence of favorable and unfavorable world-states. Must intelligence in general and artificial intelligence in particular have a way of classifying world-states as favorable or unfavorable?  </p><br>""",ai
"""<p>I'm not talking about mass scale <a href=""https://en.wikipedia.org/wiki/Skynet_(Terminator)"" rel=""nofollow"">Skynet</a> or something, but for example <a href=""http://ethereum.stackexchange.com/"">Ethereum</a> (or <a href=""http://ethereum.stackexchange.com/q/4120/105"">similar</a>) which is a public blockchain-based distributed computing platform (like <a href=""http://ethereum.stackexchange.com/a/762/105"">internet</a>) featuring smart contracts which can be executed on a decentralized virtual machine. They call it a <em>World Computer</em>.</p><br><br><p>Where there any attempts to use similar blockchain-based technology driven by community (or not) in order to create an artificial intelligence into a decentralized public blockchain-based distributed computing platform where it <a href=""http://www.newsereum.com/newsereum/can-ethereum-shut/"" rel=""nofollow"">cannot be shutdown</a>?</p><br>""",ai
"""<p>For example, search engine companies want to classify their image searches into 2 categories (which they already do that) such as: <a href=""https://en.wikipedia.org/wiki/Not_safe_for_work"" rel=""nofollow"">NSFW</a> (nudity, porn, brutality) and safe to view pictures.</p><br><br><p>How can artificial neural networks achieve that, and at what success rate? Can they be easily mistaken?</p><br>""",ai
"""<p>Do scientists or research experts know from the kitchen what is happening inside complex ""deep"" neural network with at least millions of connections firing at an instant? Do they understand the process behind this (e.g. what is happening inside and how it works exactly), or it is a subject of debate?</p><br><br><p>For example this <a href=""https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf"">study</a> says:</p><br><br><blockquote><br>  <p>However there is no clear understanding of <em>why</em> they perform so well, or <em>how</em> they might be improved.</p><br></blockquote><br><br><p>So does it mean the scientists actually doesn't know how complex convolutional network models work?</p><br>""",ai
"""<p>Is there any way to estimate how big the neural network would be after training session of 100,000 unlabeled images for unsupervised learning (like in <a href=""https://cs.stanford.edu/~acoates/stl10/"" rel=""nofollow"">STL-10 dataset</a>: 96x96 pixels and color)?</p><br><br><p>Not the storage space (because this could vary I guess based on the implementation), but specifically how many neurons it could have. It could be an estimate (e.g. in thousand, millions). If it depends, then on what? Are there any figures that can be estimated?</p><br>""",ai
"""<p>For example I'd like to train my neural network to recognize the type of actions (e.g. in commercial movies or some real life videos), so I can ""ask"" my network in which video or movie (and at what frames) somebody was driving a car, kissing, eating, was scared or was talking over the phone.</p><br><br><p>What are the current successful approaches to that type of problem?</p><br>""",ai
"""<p>For example I would like to implement transparent AI in the RTS game which doesn't offer any AI API (like old games), and I'd like to use image recognition algorithm for detecting the objects which can talks to another algorithm which is responsible for the logic.</p><br><br><p>Given I'd like to use two neural networks, what are the approaches to setup the communication between them? Is it just by exporting result findings of the first algorithm (e.g. using CNN) with list of features which were found on the screen, then use it as input for another network? Or it's more complex than that, or I need to have more than two networks?</p><br>""",ai
"""<p>Were there any successful attempts to replace poor guide dogs used for blind people with AI to achieve similar rate of success? I guess dogs could be easily distracted and not reliable for every situation, and it probably takes less time to train AI, than a dog.</p><br>""",ai
"""<p>Do we know why Tesla's Autopilot mistaken empty sky with a high-sided lorry which resulted in fatal crash involving a car in self-drive mode? Was it AI fault or something else? Is there any technical explanation behind this why this happened?</p><br><br><p>References: <a href=""http://news.sky.com/story/tesla-driver-in-first-self-drive-fatal-crash-10330121"" rel=""nofollow"">Sky News article</a>, <a href=""http://www.theverge.com/2016/6/30/12072408/tesla-autopilot-car-crash-death-autonomous-model-s"" rel=""nofollow"">The Verge</a>.</p><br>""",ai
"""<p>For benefits of testing AGI, is using a high-level video game description language (VGDL) gives more reliable and accurate results of general intelligence than using Arcade Learning Environment (ALE)?</p><br>""",ai
"""<p>Some time ago playing chess was challenging for algorithms, then Go game which is vastly more complex than compared to chess.</p><br><br><p>How about playing RTS game which have enormous branching factors limited by its time and space (like deciding what to do next)? What are the successful approaches to such problems?</p><br>""",ai
"""<p>We can read on wiki page that in March 2016 AlphaGo AI lost its game (1 of 5) to Lee Sedol, a professional Go player. One <a href=""http://www.bbc.co.uk/news/technology-36558829"" rel=""nofollow"">article</a> cite says:</p><br><br><blockquote><br>  <p>AlphaGo lost a game and we as researchers want to explore that and find out what went wrong. We need to figure out what its weaknesses are and try to improve it.</p><br></blockquote><br><br><p>Have researchers already figured it out what went wrong?</p><br>""",ai
"""<p>Assuming we're dealing with artificial neural network (e.g. using <a href=""https://en.wikipedia.org/wiki/Convolutional_neural_network"" rel=""nofollow"">convnets</a>) which was trained by large dataset of human faces.</p><br><br><p>Are there any known issues or challenges where facial recognition would fail? I'm not talking about covering half of the face, but some simple common things such as wearing the glasses, hat, jewellery, having face painting or tattoo, can this successfully prevent AI from recognizing the face? If so, what are current methods dealing with such challenges?</p><br>""",ai
"""<p>I would like to know what kind of dataset I need (to prepare) for training the network to recognize the spelling mistakes in individual words for English text.</p><br><br><p>Given the large database of words, having correct one for each incorrect. What kind of input is more efficient for that tasks? Is it using one input per each letter, syllable, whole word or I should use different pattern syllable?</p><br><br><p>Then the input should be incorrect word, output correct, and if the word doesn't need correction, then both input and output should be the same. Is that the right approach?</p><br>""",ai
"""<p>I believe <em>artificial intelligence</em> (AI) term is overly overused nowadays.</p><br><br><p>For example people see that something is self-moving and they call it AI, even if it's on autopilot (like cars or planes) or there is some simple algorithm behind it.</p><br><br><p>What are the minimum general requirements so that we can say something is AI?</p><br>""",ai
"""<p>I believe normally you can use <a href=""https://en.wikipedia.org/wiki/Genetic_programming"" rel=""nofollow"">genetic programming</a> for sorting, however I'd like to check whether it's possible using ANN.</p><br><br><p>Given the unsorted text data from input, which neural network is suitable for doing sorting tasks?</p><br>""",ai
"""<p>I've read on wiki that <a href=""https://en.wikipedia.org/wiki/Genetic_programming"" rel=""nofollow"">genetic programming</a> has '<em>outstanding results</em>' in cyberterrorism prevention.</p><br><br><p>Further more, this <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=877981"" rel=""nofollow"">abstract</a> says:</p><br><br><blockquote><br>  <p>Using machine-coded linear genomes and a homologous crossover operator in genetic programming, promising results were achieved in detecting malicious intrusions.</p><br></blockquote><br><br><p>I've checked the study, but it's still not clear for me.</p><br><br><p>How exactly was this detection achieved from the technical perspective?</p><br>""",ai
"""<p>On <a href=""https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)"" rel=""nofollow"">Wikipedia</a> we can read:</p><br><br><blockquote><br>  <p>Kasparov accused IBM of cheating and demanded a rematch. IBM refused and retired Deep Blue.</p><br></blockquote><br><br><p>What was the accusation and how was Deep Blue allegedly able to cheat?</p><br>""",ai
"""<p>The Wikipedia page describes <a href=""https://en.wikipedia.org/wiki/AI_control_problem"" rel=""nofollow"">AI control problem</a> in very intricated way.</p><br><br><p>Therefore I would like to better understand it based on some simple explanation, what's going on.<br>Basically I don't want any copy &amp; pastes from wiki, because the articles there are written in neutral point of view, in very general way where articles are evolving very slowly, so the definition from there doesn't suit me.</p><br><br><p>I believe this is what is discussed nowadays by government and it's important aspects of AI technology where it leds to.<br>I believe this could be a big problem in the near future, so I'm expecting to hear about this from people from much better and more up-to-date point of view.</p><br><br><p>So what is exactly the AI Control Problem?</p><br>""",ai
"""<p>According to <a href=""http://en.wikipedia.org/wiki/Prolog"">Wikipedia</a>,</p><br><br><blockquote><br>  <p>Prolog is a general-purpose logic programming language associated with artificial intelligence and computational linguistics.</p><br></blockquote><br><br><p>Is it still used for AI?</p><br><br><hr><br><br><p><sub>This is based off of a question on the 2014 closed beta. The author had the UID of 330.</sub></p><br>""",ai
"""<p>Ideally I'd like to watch movie which is deep dreamed in real-time. Most algorithms which I know are too slow or not designed for real-time processing.</p><br><br><p>For example I'm bored with some movie which I've watched thousands of time and I'd like to add some ""dreaming"" to it which is real-time filter which takes input frames, then it's processing and enhances the images through artificial neural network to achieve doodled output.</p><br><br><p>Doesn't have to be exactly <a href=""https://en.wikipedia.org/wiki/DeepDream"" rel=""nofollow"">DeepDream</a> or hallucinogenic technique (which could be too much to watch for 2h), but with any similar ANN algorithm. I'm more interested into achieving desired real-time use.</p><br><br><p>What kind of techniques can achieve such efficiency?</p><br>""",ai
"""<p>How does employing evolutionary algorithms to design and train artificial neural networks have advantages over using the conventional backpropagation algorithms?</p><br>""",ai
"""<p>Are there any existing approaches for using artificial neural networks (ANN) or evolutionary algorithm (EA) for detecting coding standard violations? Which one would be more suitable?</p><br><br><p>I don't have any specific programming language in mind, but something similar to <a href=""http://pear.php.net/package/PHP_CodeSniffer"" rel=""nofollow"">PHP_CodeSniffer</a> (following <a href=""https://www.drupal.org/coding-standards"" rel=""nofollow"">these standards</a>), but instead of using hardcoded rules, the algorithm should learn good techniques, but I'm not sure based on what training data. How would you approach the training session, any suggestions?</p><br>""",ai
"""<p>Genetic Algorithms has come to my attention recently when trying to correct/improve computer opponents for turn-based strategy computer games.</p><br><br><p>I implemented a simple Genetic Algorithm that didn't use any cross-over, just some random mutation. It seemed to work in this case, and so I started thinking:</p><br><br><p><strong>Why is cross-over a part of genetic algorithms? Wouldn't mutation be enough?</strong></p><br><br><p><sub>This is from a data dump on an old AI site. The asker had the UID of 7. </sub></p><br>""",ai
"""<p>Based on this <a href=""http://www.dailymail.co.uk/sciencetech/article-3677950/Google-s-self-driving-cars-spot-cyclists-Sensors-read-hand-signals-predict-riders-behavior.html"" rel=""nofollow"">article</a>, Google's self-driving cars can spot cyclists, cars, road signs, markings, traffic lights, and pedestrians.</p><br><br><p>How exactly does it identify pedestrians? Is it based on face recognition, shape, size, distance, infrared signature?</p><br>""",ai
"""<p>In <a href=""https://www.technologyreview.com/s/530276/hidden-obstacles-for-googles-self-driving-cars/"">Hidden Obstacles for Google’s Self-Driving Cars</a> article we can read that:</p><br><br><blockquote><br>  <p>Google’s cars can detect and respond to stop signs that aren’t on its map, a feature that was introduced to deal with temporary signs used at construction sites.</p><br>  <br>  <p>Google says that its cars can identify almost all unmapped stop signs, and would remain safe if they miss a sign because the vehicles are always looking out for traffic, pedestrians and other obstacles.</p><br></blockquote><br><br><p>What would happen if a car spotted somebody in front of it (but not on the collision path) wearing a T-shirt that has a stop sign printed on it. Would it react and stop the car?</p><br>""",ai
"""<p><sub> This is a scope experiment. </sub></p><br><br><hr><br><br><p>After Google/Tesla/whoever else is making self-driving cars finishes perfecting them, will they replace the cars with human drivers, so that there are only self-driving cars?</p><br><br><p>If they do, it would probably make the roads safer.</p><br>""",ai
"""<p>Significant AI vs human board game matches include:</p><br><br><ul><br><li><strong>chess</strong>: <a href=""https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)#Deep_Blue_versus_Kasparov"" rel=""nofollow"">Deep Blue vs Kasparov</a> in 1996,</li><br><li><strong>Go</strong>: <a href=""https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol"" rel=""nofollow"">DeepMind AlphaGo vs Lee Sedol</a> in 2016,</li><br></ul><br><br><p>which demonstrated that AI challenged and defeated professional players.</p><br><br><p>Are there known board games left where a human can still win against an AI? I mean based on the final outcome of authoritative famous matches, where there is still same board game where AI cannot beat a world champion of that game.</p><br>""",ai
"""<p>Has there any research been done on how difficult certain languages are to learn for chatbots? <br>For example, CleverBot knows a bit of Dutch, German, Finnish and French, so there are clearly chatbots that speak other languages than English. (English is still her best language, but that is because she speaks that most often)</p><br><br><p>I would imagine that a logical constructed language, like lobjan, would be easier to learn than a natural language, like English, for example.  </p><br>""",ai
"""<p>Google, Tesla, Apple etc have all built or are building their own self-driving cars. As an expert in a related area, I am interested in knowing at a high level, the systems and techniques that go into self-driving cars. How easy is it for me to make a tabletop prototype (large enough to accomodate the needed computing power needs)?</p><br>""",ai
"""<p>The above question itself is perhaps too broad for this forum, hence I am phrasing it as a request for references.</p><br><br><p>Humans have been endowed with personalities by nature, and it is not clear (to me at least) if this is a feature or a bug. This has been explored in science fiction by various notions of <a href=""http://memory-alpha.org/Borg"" rel=""nofollow"">Borg</a>-like entities. It is my belief that, for narrative reasons, such stories usually end with the humans with their flawed personalities winning in the end. </p><br><br><p>Are there experts who have analyzed, perhaps mathematically, design criteria for an AI agent with weakly enforced goals (eg. to maximize reproduction in the human case) in an uncertain environment, and ended up with the answer that a notion of personality is useful? If there are philosophers or science fiction writers who have examined this question in their work, I would be happy to know about those too.</p><br>""",ai
"""<p>I'm looking for research which discusses misbehavior detection in public internet access networks using ANN approaches.</p><br><br><p>So it can be used by <a href=""https://en.wikipedia.org/wiki/Internet_service_provider"" rel=""nofollow"">ISP</a> to detect suspicious users connected to their network.</p><br>""",ai
"""<p>I'm investigating applications of AI algorithms which can be used for data leakage detection and prevention within an intranet network (like <a href=""https://en.wikipedia.org/wiki/Forcepoint"" rel=""nofollow"">Forcepoint</a>). More specifically detecting traffic patterns. I'm new to this.</p><br><br><p>Which learning algorithms are most suitable for this goal? <a href=""https://en.wikipedia.org/wiki/Evolutionary_algorithm"" rel=""nofollow"">EA</a>, <a href=""https://en.wikipedia.org/wiki/Genetic_algorithm"" rel=""nofollow"">GA</a>, <a href=""https://en.wikipedia.org/wiki/Artificial_neural_network"" rel=""nofollow"">ANN</a> (which one) or something else?</p><br>""",ai
"""<p>I'm wondering, instead of implementing new web browsers over and over again with millions line of code which is very difficult to manage, would it be possible to use ANN or GA algorithm to teach it about the rendering process (how the page should look like)?</p><br><br><p>So as an input I would imaging the html source code, output is the rendered page (maybe in some interactive image like SVG, some library or something, I'm not sure).</p><br><br><p>The training data can be dataset of websites providing input source code and their rendered representation by using other browsers for the guidance as expected output.</p><br><br><p>Which approach would you take and what are the most challenging things you can think of?</p><br>""",ai
"""<p>I'm trying to make a conversational chatbot, so the user inputs are quite wide ranging - beyond just ""turn lights on"". I want to detect the category of the user intents from their inputs and prepare responses.</p><br><br><p>I've looked at MS' Luis and api.ai and the intents require a lot of training. Can people suggest other techniques for untrained intent detection?</p><br><br><p>For example if the user says ""Pasta is my favorite dish to cook"" then detect ""intent preference entity pasta"" - then I can gradually build up responses to different categories of inputs.</p><br><br><p>Perhaps the crowd-sourced intents that wit.ai (facebook) has access to could do this but I'm not sure if all end-users have access to those models.</p><br>""",ai
"""<p>How does a domestic autonomous robotic vacuum cleaner -  such as a <a href=""https://en.wikipedia.org/wiki/Roomba"" rel=""nofollow"">Roomba</a> - know when it's working cleaned area (aka virtual map), and how does it plan to travel to the areas which hasn't been explored yet?</p><br><br><p>Does it use some kind of <a href=""https://en.wikipedia.org/wiki/A*_search_algorithm"" rel=""nofollow"">A*</a> algorithm?</p><br>""",ai
"""<p>It has been <a href=""http://www.itnonline.com/content/will-fda-be-too-much-intelligent-machines"" rel=""nofollow"">suggested</a> that machine learning algorithms (also <a href=""http://ai.stackexchange.com/q/1427/8"">Watson</a>) can help with finding disease in patient images and optimize scans. Also that deep learning algorithms show promise for every type of digital imaging.</p><br><br><p>How does exactly deep learning algorithms exactly can find suspicious patterns in the body’s biochemistry?</p><br>""",ai
"""<p>The <a href=""https://www.youtube.com/watch?v=AplG6KnOr2Q"" rel=""nofollow"">Mario Lives!</a> video (and its follow-up video, <a href=""https://www.youtube.com/watch?v=ltPj3RlN4Nw&amp;list=PLuOoXrWK6Kz5ySULxGMtAUdZEg9SkXDoq&amp;index=5"" rel=""nofollow"">Mario Becomes Social!</a>) showcases an AI unit that is able to simulate emotional desicion-making within a virtual world, and can enter into ""emotional states"" such as curiosity, hunger, happiness, and fear. While this seems cool and exciting (especially for video game AI), I am confused how this would be useful in real-world scenarios.</p><br><br><p>What would be the point of building autonomous actors that would behave based on these emotional states, instead of simply knowing <em>what</em> they should do (either by hardcoding in the rules, or learning the rules through machine learning)?</p><br>""",ai
"""<p><sub>This is from the 2014 closed beta. The asker had the UID of 245.</sub></p><br><br><p>For a deterministic problem space, I need to find a neural network with the optimal node and link structure. I want to use a genetic algorithm to simulate many neural networks to find the best network structure for the problem domain.</p><br><br><p>I know a fair amount about neural networks<sup>1</sup> but have not used genetic algorithms for a task like this before.</p><br><br><p>What are the practical considerations? <br>How should I encode the structure into a genome?</p><br><br><hr><br><br><p><sub><sup>1</sup>Actually, I don't. Just saying that. -Mithrandir. </sub></p><br>""",ai
"""<p>Were there any studies which checked the accuracy of neural network predictions of greyhound racing results, compared to a human expert? Would it achieve a better payoff?</p><br>""",ai
"""<p>I've read about The Loebner Prize for AI, which pledged a Grand Prize of $100,000 and a Gold Medal for the first computer whose responses were indistinguishable from a human's.</p><br><br><p>So I was wondering whether any chatbots have fooled the judges and won a Gold Medal yet?</p><br><br><p>From their <a href=""http://www.loebner.net/Prizef/loebner-prize.html"" rel=""nofollow"">website</a> this isn't clear (as some of the links doesn't load).</p><br><br><hr><br><br><p>A few highlights from previous years:</p><br><br><p><a href=""http://loebner.exeter.ac.uk/results/"" rel=""nofollow"">2011 Loebner Prize results</a></p><br><br><blockquote><br>  <p>None of the AI systems fooled the judges, therefore the Turing Test has not been passed.</p><br></blockquote><br><br><p><a href=""http://www.paulmckevitt.com/loebner2013/scoring/loebner2013leaderboard.txt"" rel=""nofollow"">Loebner 2013 results</a>:</p><br><br><blockquote><br>  <p>No chatbot fooled any of the 4 Judges.</p><br></blockquote><br>""",ai
"""<p>Hypothetically, assume that you have access to infinite computing power. Do we have designs for any brute-force algorithms that can find an AI capable of passing traditional tests (e.g. Turing, Chinese Room, MIST, etc.)? </p><br>""",ai
"""<p>I'm aware this could be a complex topic, however I'm interested in existing research projects or studies where people are attempting or have succeeded in teaching an AI a foreign language just by training/teaching it from English books. By reading, analysing and understanding, so that it knows the foreign language's rules (such as grammar, spelling, etc.), the same way as a human would learn. The language doesn't have to be Chinese, which is difficult for even humans to learn.</p><br>""",ai
"""<p>Would it be possible to put Asimov's three Laws of Robotics into an AI?</p><br><br><p>The three laws are:</p><br><br><ol><br><li><p>A robot (or, more accurately, an AI) cannot harm a human being, or through inaction allow a human being to be harmed<sup>1</sup></p></li><br><li><p>A robot must listen to instructions given to it by a human, as long as that does not conflict with the first law.</p></li><br><li><p>A robot must protect its own existence, if that does not conflict with the first two laws.</p></li><br></ol><br><br><hr><br><br><p><sup>1</sup> <em>To it's knowledge</em>. This was a plot point in one of the books :P</p><br>""",ai
"""<p>For Example:</p><br><br><h2>Could you provide reasons why a sundial is <em>not</em> ""intelligent""?</h2><br><br><p>A sundial senses its environment and acts rationally. It outputs the time. It also stores  percepts. (The numbers the engineer wrote on it.)</p><br><br><h2>What properties of a self driving car would make it ""intelligent""?</h2><br><br><p>Where is the line between non intelligent matter and an intelligent system?</p><br>""",ai
"""<p>We can read on <a href=""https://en.wikipedia.org/wiki/TensorFlow#Tensor_processing_unit_.28TPU.29"" rel=""nofollow"">Wikipedia page</a> that Google built a custom ASIC chip for machine learning and tailored for TensorFlow which helps to accelerate AI.</p><br><br><p>Since ASIC chips are specially customized for one particular use without the ability to change its circuit, there must be some fixed algorithm which is invoked.</p><br><br><p>So how exactly does the acceleration of AI using ASIC chips work if its algorithm cannot be changed? Which part of it is exactly accelerating?</p><br>""",ai
"""<p>I was reading that the <a href=""http://nasa-jsc-robotics.github.io/valkyrie/"" rel=""nofollow"">Valkyrie robot</a> was originally designed to 'carry out search and rescue missions'.</p><br><br><p>However there were some talks to send it to Mars to assist astronauts.</p><br><br><p>What kind of specific trainings or tasks are planned for 'him' to be able to carry on its own?</p><br><br><p>Refs:</p><br><br><ul><br><li><a href=""https://github.com/nasa-jsc-robotics"" rel=""nofollow"">NASA-JSC-Robotics at GitHub</a></li><br><li><a href=""http://nasa-jsc-robotics.github.io/valkyrie/"" rel=""nofollow"">github.io page</a></li><br><li><a href=""https://gitlab.com/nasa-jsc-robotics/valkyrie"" rel=""nofollow"">gitlab page</a></li><br></ul><br>""",ai
"""<p>Do scientists know by what mechanism biological brains/biological neural networks store data?</p><br><br><p>I was thinking about @kenorbs <a href=""http://ai.stackexchange.com/questions/1656/how-can-nanobot-implants-in-our-brains-connect-to-the-internet"">question</a> about implanting nanobots to build an AGI on top of human wetware. </p><br><br><p>I only have a vague notion that we store data in our brains by altering synapses? </p><br><br><p>Links, Criticism and Detailed Explanation welcome.</p><br><br><p>I also would love a decent description of how a vanilla Artificial Neural Network stores data. </p><br><br><p><strong>Questions:</strong></p><br><br><ol><br><li><p>How is data stored in a biological Neural Network?</p></li><br><li><p>How is data stored in an Artificial Neural Network?</p></li><br></ol><br>""",ai
"""<p>My understanding is that <em>Watson</em> is the name of the computer, and <em>DeepQA</em> is the name of the software or technology. They are both correlated.</p><br><br><p>Are there any computers/technologies other than <em>Watson</em> which <strong>are using <em>DeepQA</em></strong>? Or is <em>Watson</em> the only computer which implements that software/technology?</p><br><br><p><sup>This question is inspired by this <a href=""http://meta.ai.stackexchange.com/q/1177/8"">meta thread</a>.</sup></p><br>""",ai
"""<p>There is a study about <a href=""http://www.aclweb.org/anthology/P/P02/P02-1031.pdf"" rel=""nofollow"">The Necessity of Parsing for Predicate Argument Recognition</a>, however I couldn't find much information about 'Predicate Argument Recognition' which could explain it.</p><br><br><p>What is it exactly and how does it work, briefly?</p><br>""",ai
"""<p>The Wit.ai is a Siri-like voice interface which can can parse messages and predict the actions to perform.</p><br><br><p>Here is the <a href=""https://labs.wit.ai/demo/index.html"" rel=""nofollow"">demo site powered by Wit.ai</a>.</p><br><br><p>How does it understand the spoken sentences and convert them into structured actionable data? Basically, how does it know what to do?</p><br>""",ai
"""<p>In 2014 <a href=""https://techcrunch.com/2014/02/06/linkedin-snatches-up-data-savvy-job-search-startup-bright-com-for-120m-in-its-largest-acquisition-to-date/"" rel=""nofollow"">Linkedin acquired Bright.com</a>, for $120 million and it is using AI and big data algorithms to connect users.</p><br><br><blockquote><br>  <p>Bright also throws in a little Klout, ranking people by a “Bright score” which it uses to assess how strong the chemistry is between a user and a particular job.</p><br>  <br>  <p>It also takes into account historical hiring patterns into its matching, along with account location, a user’s past experience and synonyms.</p><br></blockquote><br><br><p>In brief, is it known (based on some research papers) how such algorithm works which aiming at scoring 'chemistry' between users and their jobs?</p><br>""",ai
"""<p>According to this <a href=""http://mashable.com/2014/01/06/pinterest-acquires-visualgraph/"" rel=""nofollow"">article</a>, Pinterest acquired VisualGraph, an image recognition and visual search technology startup.</p><br><br><p>How does Pinterest apply VisualGraph technology for machine vision, image recognition and visual search in order to classify the images?</p><br><br><p>In short, how do they predict the image categories? Based on what features?</p><br>""",ai
"""<p>Wolfram Language Image Identification Project launched an <a href=""https://www.imageidentify.com/"" rel=""nofollow"">Image Identify site</a> demo which returns the top predicted tags for the photos.</p><br><br><p>How does it work, briefly? I mean what type of learning vision technologies are used to analyze, recognize and understand the content of an image?</p><br>""",ai
"""<p>Inspired by <a href=""http://ai.stackexchange.com/q/1481/8"">this discussion</a> about recognizing human actions, I have found the <a href=""https://github.com/harishrithish7/Fall-Detection"" rel=""nofollow"">Fall-Detection</a> project which detects humans falling on the ground from a CCTV camera feed, and which can consider alerting the hospital authorities.</p><br><br><p>My question is, are there any existing real-life implementations or research projects <strong>which specifically use live video feed from the surveillance cameras in order to detect crime</strong> using convnets (or similar approaches)? If so, how do they work, briefly? Do they automatically inform the police about the crime with the details what happened and where?</p><br><br><p>For example car accidents, physical assaults, robberies, violent disturbances, weapon attacks, etc.</p><br>""",ai
"""<p>I have gone through the <a href=""https://en.wikipedia.org/wiki/Statistical_relational_learning"">wikipedia explanation of SRL</a>. But, it only confused me more:</p><br><br><blockquote><br>  <p>Statistical relational learning (SRL) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure.</p><br></blockquote><br><br><p>Can someone give a more dumbed down explanation of the same, preferably with an example?</p><br>""",ai
"""<p>The obvious solution is to ensure that the training data is balanced - but in my particular case that is impossible. What corrections can one perform in such a scenario?</p><br><br><p>I know that my training data is heavily biased towards a particular class, say, and I cannot change that. Moreover, the labels are very noisy. Conditioned on this piece of information, is there anything I can do by tweaking the training process itself/ something else, to correct for the bias in the training data?</p><br><br><p>The data comes from an experiment (from an electron microscope), and I cannot collect more data. It's always going to be biased in this way, so alternatively-biased is also not an option. I'm sorry that I'm unable to provide any more details due to confidentiality.</p><br>""",ai
"""<p><strong>Note:</strong> I wanted to ask a meta-post first to see if this site was supposed to be used only for AI-related questions, or if AI-related questions such as this were allowed, too, but apparently you need to have asked five actual questions first.</p><br><br><hr><br><br><p>I'm going to be entering a masters computer science program in the fall, and I wanted to move towards a concentration in computational neuroscience and linguistics for AI development applications. While I have a math and CS background, I have almost no biology/neuroscience background, and my linguistics background is limited to the random research I've done in my spare time to satiate my curiosities.</p><br><br><p>What are good non-math and CS related topics to study for these fields? </p><br>""",ai
"""<p>What regulations are already in place regarding Artificial General Intelligences? What reports or recommendations prepared by official government authorities were already published?</p><br><br><p>So far I know of <a href=""http://www.ft.com/cms/s/2/5ae9b434-8f8e-11db-9ba3-0000779e2340.html"">Sir David King's report done for UK government</a>.</p><br>""",ai
"""<p>Most introductions to the field of MDPs and Reinforcement learning focus exclusively on domains where space and action variables are integers (and finite).<br><br>This way we are introduced quickly to Value Iteration, Q-Learning and the like.</p><br><br><p>However the most interesting applications (say, <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.3518&amp;rep=rep1&amp;type=pdf"" rel=""nofollow"">flying helicopters</a>) of RL and MDPs involve continuous state space and action spaces.<br><br>I'd like to go beyond basic introductions and focus on these cases but I am not sure how to get there. </p><br><br><p>Are there any research projects or studies that deal with these cases in depth?</p><br>""",ai
"""<p>Can someone explain to me the difference between machine learning and deep learning? Is it possible to learn deep learning without knowing machine learning?</p><br>""",ai
"""<p>By new, unseen examples; I mean like the animals in <a href=""https://en.wikipedia.org/wiki/No_Man%27s_Sky"">No Man's Sky</a>. </p><br><br><p>A couple of images of the animals are:<br><a href=""http://i.stack.imgur.com/zS0rX.jpg""><img src=""http://i.stack.imgur.com/zS0rX.jpg"" alt=""enter image description here""></a></p><br><br><p><a href=""http://i.stack.imgur.com/Ir1Qt.jpg""><img src=""http://i.stack.imgur.com/Ir1Qt.jpg"" alt=""enter image description here""></a></p><br><br><p>So, upon playing this game, I was curious <strong>about how good is AI at generating visual characters or examples?</strong></p><br>""",ai
"""<p>I wanted to know what the differences between hyper-heuristics and meta-heuristics are, and what their main applications are. Which problems are suited to be solved by Hyper-heuristics?</p><br>""",ai
"""<p>What is the difference between agent function and agent program with respect to percept sequence?</p><br><br><p>In the book <em>""Artificial Intelligence: A modern approach""</em>,</p><br><br><blockquote><br>  <p>The agent function, notionally speaking, takes as input the entire<br>  percept sequence up to that point, whereas the agent program takes the<br>  current percept only.</p><br></blockquote><br><br><p>Why does the agent program only take current percept. Isn't it just implementation of the agent function?</p><br>""",ai
"""<p>Are there currently any studies to simulate gradual (or sudden) implementation of AIs in the general work force?</p><br>""",ai
"""<p>In <a href=""https://en.wikipedia.org/wiki/Portal_2"">Portal 2</a> we see that AI's can be ""killed"" by thinking about a paradox.</p><br><br><p><a href=""http://i.stack.imgur.com/wkUSC.png""><img src=""http://i.stack.imgur.com/wkUSC.png"" alt=""Portal Paradox Poster""></a></p><br><br><p>I assume this works by forcing the AI into an infinite loop which would essentially ""freeze"" the computer's consciousness.</p><br><br><p><strong>Questions:</strong> Would this confuse the AI technology we have today to the point of destroying it? <br> If so, why? And if not, could it be possible in the future?</p><br>""",ai
"""<p>In the 1950's, there were widely-held beliefs that ""Artificial Intelligence"" will quickly become both self-conscious and smart-enough to win chess with humans. Various people suggested time frames of e.g. 10 years (see Olazaran's ""Official History of the Perceptron Controversy"", or let say 2001: Space Odyssey).</p><br><br><p>When did it become clear that making computers play games like chess is not equal to AGI? Who was the first person to postulate separation of the concept of AGI from task-specific methods?</p><br>""",ai
"""<p>We hear a lot today about how <a href=""http://deeplearning4j.org/thoughtvectors"" rel=""nofollow"">thought vectors</a> are the <a href=""http://www.extremetech.com/extreme/206521-thought-vectors-could-revolutionize-artificial-intelligence"" rel=""nofollow"">Next Big Thing in AI</a>, and how they serve as the underlying representation of thought/knowledge in ANN's.  But how can one use thought vectors in other regimes, especially including symbolic logic / GOFAI?  Could thought vectors be the ""substrate"" that binds together probabilistic approaches to AI and approaches that are rooted in logic?  </p><br>""",ai
"""<p>I'm currently working with the CHILDES corpus trying to create a classifier that distinguishes children whom suffer from specific language impairment (SLI) from those who are typically developing (TD).</p><br><br><p>In my readings I noticed that there really isn't a convincing set of features to distinguish the two that have been discovered yet, so I came upon the idea of trying to create a feature learning algorithm that could potentially make better ones.  </p><br><br><p>Is this possible? If so how do you suggest I approach this? From the reading I have done, most feature learning is done on image processing. Another problem is the dataset I have is potentially too small to make it work (in the 100's) unless I find a way to get more transcripts from children.</p><br>""",ai
"""<p>An AI box is a (physical) barrier preventing an AI from using too much of his environment to accomplish his final goal. For example, an AI given the task to check, say, 10<sup>50</sup> cases of a mathematical conjecture as fast as possible, might decide that it would be better to also take control over all other computers and AI to help him. </p><br><br><p>However, an transhuman AI might be able to talk to a human until the human lets him out of the box. In fact, <a href=""http://www.yudkowsky.net/singularity/aibox/"" rel=""nofollow"">Eliezer Yudowsky</a> has conducted an experiment twice, where he played the AI and he twice convinced the Gatekeeper to let him out the box. However, he does not want to reveal what methods he used to get out of the box.</p><br><br><p><strong>Questions:</strong> Are there conducted any similiar experiments? <br> If so, is it known what methods were used to get out in those experiments?</p><br>""",ai
"""<p><em>""An artificial or constructed language (sometimes called a conlang) is a language that has been created by a person or small group, instead of being formed naturally as part of a culture.""</em> (<a href=""https://simple.wikipedia.org/wiki/Constructed_language"" rel=""nofollow"">Source: Simply English Wikipedia</a>)</p><br><br><p>My question is, could an AI make construct it's own natural language, with words, conjugations and grammar rules? Basically, a language that humans could use to speak to each other. (Preferably to communicate abstract, high-level concepts.)</p><br><br><p>What techniques could such an AI use? Could it be based on existing natural languages or would it have few connections to existing natural languages? Could it design a language that's easier to learn than existing languages (even <a href=""https://en.wikipedia.org/wiki/Esperanto"" rel=""nofollow"">Esperanto</a>)?</p><br>""",ai
"""<p>I'm reading such nonsense about how an AI would turn the world into a supercomputer to solve a problem that it thought it needed to solve. That wouldn't be AI. That's procedural programming stuck in some loop nonsense. An AI would need to evolve and re-organise its neurons. It wouldn't be stuck to hardcode if it becomes intelligent by re-writing its code.</p><br>""",ai
"""<p>I'm in the process of learning as much about chatbots/CUI applications as possible and I'm trying to find more information on some of the major players in this field. By this, I mean any execs, developers, academics, designers, etc. who are doing cutting edge things. Some examples could be David Marcus (VP of messaging products at Facebook) or Adam Cheyer (VP of engineering at Viv).</p><br>""",ai
"""<p>How big artificial neural networks can we run now (either with full train-backprop cycle or just evaluating network outputs) if our total energy budget for computation is equivalent to human brain energy budget (<a href=""http://www.scientificamerican.com/article/thinking-hard-calories/"">12.6 watts</a>)?</p><br><br><p>Let assume one cycle per second, which seems to roughly match the <a href=""http://www.jneurosci.org/content/31/45/16217.full"">firing rate of biological neurons</a>.</p><br>""",ai
"""<p>Let's suppose that we have a legacy system in which we don't have the source code and this system is on a mainframe written in Cobol. Is there any way using machine learning in which we can learn from the inputs and outputs the way the executables work? Doing this analysis could lead to develop some rest / soap webservice that can substitute the legacy system in my opinion. </p><br>""",ai
"""<p>Sometimes I understand that people doing <em>cognitive science</em> try to avoid the term <em>artificial intelligence</em>. The feeling I get is that there is a need to put some distance to the <a href=""https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence"" rel=""nofollow"">GOFAI</a>.</p><br><br><p>Another impression that I get is that <em>cognitive science</em> is more about trying to find out how the human <em>intelligence</em>(?)... <em>Mind</em>? works... And that it would use <em>artificial intelligence</em> to make tests or experiments, to test ideas and so forth...</p><br><br><p>Is Artificial Intelligence (only) a research tool for Cognitive Science?</p><br><br><p><strong>What is the difference between Artificial Intelligence and Cognitive Science?</strong></p><br>""",ai
"""<p>Roger Schank did some interesting work on language processing with Conceptual Dependency (CD) in the 1970s. He then moved somewhat out of the field, being in Education these days. There were some useful applications in natural language generation (BABEL), story generation (TAILSPIN) and other areas, often involving planning and episodes rather than individual sentences.</p><br><br><p>Has anybody else continued to use CD or variants thereof? I am not aware of any other projects that do, apart from Hovy's PAULINE which uses CD as representation for the story to generate.</p><br>""",ai
"""<p>I have been wanting to get started learning about artificial intelligence but I know almost nothing about coding or anything. So my question is, what would be the best way to get started in learning about artificial intelligence, as in should I learn some kind of coding language or is there some kind of other concept you need to know before getting started. So I'm just kind of looking for the best way to get started if you literally know nothing.</p><br>""",ai
"""<p>I have been studying local search algorithms such as greedy hill climbing, stochastic hill climbing, simulated annealing etc. I have noticed that most of these methods take up very little memory as compared to systematic search techniques.</p><br><br><p>Are there local search algorithms that make use of memory to give significantly better answers than those algorithms that use little memory (such as crossing local maxima)? Also, is there a way to combine local search and systematic search algorithms to get the best of both worlds?</p><br>""",ai
"""<p>When I visit this site, I find the word ""search"" appears quite often. </p><br><br><p>But why is it important? What kinds of search algorithms are used in Artificial Intelligence?  And how do they improve the result of an AI?</p><br>""",ai
"""<p>Conceptually speaking, aren't artificial neural networks just highly distributed, lossy compression schemes?</p><br><br><p>They're certainly efficient at <a href=""https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Applications/imagecompression.html"" rel=""nofollow"">compressing images</a>.</p><br><br><p>And aren't brains (at least, the neocortex) just compartmentalized, highly distributed, lossy databases?</p><br><br><p>If so, what salient features in RNNs and CNNs are necessary in any given lossy compression scheme in order to extract the semantic relations that they do? Is it just a matter of having a large number of dimensions/variables? </p><br><br><p>Could some kind of lossy <a href=""https://en.wikipedia.org/wiki/Bloom_filter"" rel=""nofollow"">Bloom filter</a> be re-purposed for the kinds of problems ANNs are applied to?</p><br>""",ai
"""<p>Consciousness <a href=""http://www.iep.utm.edu/consciou/"">is challenging to define</a>, but for this question let's define it as ""actually experiencing sensory input as opposed to just putting a bunch of data through an inanimate machine."" Humans, of course, have minds; for normal computers, all the things they ""see"" are just more data. One could alternatively say that humans are <a href=""http://philosophy.stackexchange.com/a/4687"">sentient</a>, while traditional computers are not.</p><br><br><p>Setting aside the question of whether it's possible to build a sentient machine, does it actually make a difference if an AI is sentient or not? In other words, are there are tasks that are made impossible - not just more difficult - by a lack of sentience?</p><br>""",ai
"""<p>A lot of textbooks and introductory lectures typically split AI into connectionism and GOFAI (Good Old Fashioned AI). <br>From a purely technical perspective it seems that connectionism has grown into machine learning and data science, while nobody talks about GOFAI, Symbolic AI or Expert Systems at all. </p><br><br><p>Is anyone of note still working on GOFAI?    </p><br>""",ai
"""<p>Currently I work as a java developer, But very much interested in learning Artificial Intelligence.<br>Can anybody tell me what steps i have to follow to learn artificial intelligence considering the fact i am very new to this.<br>Is there any special technologies i have to learn or something else.</p><br>""",ai
"""<p>Self-Recognition seems to be an item that designers are trying to integrate into artificial intelligence. Is there a generally recognized method of doing this in a machine, and how would one test the capacity - as in a Turing-Test?</p><br>""",ai
"""<p>In the lecture, there was a statement:</p><br><br><blockquote><br>  <p>""Recurrent neural networks with multiple hidden layers are just a<br>  special case that has some of the hidden to hidden connections<br>  missing.""</p><br></blockquote><br><br><p>I understand recurrent means that can have connections to the previous layer and the same layer as well. Is there a visualization available to easily understand the above statement?</p><br>""",ai
"""<p>Inattentional Blindness is common in humans (see: <a href=""https://en.wikipedia.org/wiki/Inattentional_blindness"" rel=""nofollow"">https://en.wikipedia.org/wiki/Inattentional_blindness</a> ). Could this also be common with machines built with artificial vision?</p><br>""",ai
"""<p>My question is regarding standard dense-connected feed forward neural networks with sigmoidal activation.</p><br><br><p>I am studying Bayesian Optimization for hyper-parameter selection for neural networks. There is no doubt that this is an effective method, but I just wan't to delve a little deeper into the maths.</p><br><br><p><strong>Question:</strong> Are neural networks <a href=""http://mathworld.wolfram.com/LipschitzFunction.html"" rel=""nofollow"">Lipschitz</a> functions?</p><br>""",ai
"""<p>Can one actually kill a machine? Not only do we have problems in defining life, we also have problems in defining death. Will this also be true in artificial life and artificial intelligence?</p><br>""",ai
"""<p>Generally, people can be classified as aggressive (Type A) or passive. Could the programming of AI systems cause aggressive or passive behavior in those AIs?</p><br>""",ai
"""<p>Assuming mankind will eventually create artificial humans, but in doing so have we put equal effort into how humans will relate to an artificial human, and what can we expect in return? This is happening in real-time as we place AI trucks and cars on the road. Do people have the right to question, maybe in court, if an AI machine breaks a law?</p><br>""",ai
"""<p>AI death is still unclear a concept, as it may take several forms and allow for ""coming back from the dead"". For example, an AI could be somehow forbidden to do anything (no permission to execute), because it infringed some laws.</p><br><br><p>""Somehow forbid"" is the topic of this question. There will probably be rules, like ""AI social laws"", that can conclude an AI should ""die"" or ""be sentenced to the absence of progress"" (a jail). Then who or what could manage that AI's state?</p><br>""",ai
"""<p>Can self-driving cars deal with snow, heavy rain, or other weather conditions like these? Can they deal with unusual events, such as <a href=""http://beijingcream.com/wp-content/uploads/2012/06/Ducks-galore-2.jpeg"" rel=""nofollow"">ducks on the road</a>?</p><br><br><p><a href=""http://i.stack.imgur.com/a0PVLm.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/a0PVLm.jpg"" alt=""ducks on the road""></a></p><br>""",ai
"""<p>Most of the people is trying to answer question with a neural network. However, has anyone came up with some thoughts about how to make neural network ask questions, instead of answer questions? For example, if a CNN can decide which category an object belongs to, than can it ask some question to help the the classification?</p><br>""",ai
"""<p>The Mars Exploration Rover (MER) <em><a href=""http://www.nasa.gov/mp4/618340main_mer20120124-320-jpl.mp4"" rel=""nofollow"">Opportunity</a></em> landed on Mars on January 25, 2004. The rover was originally designed for a 90 <strong>Sol mission</strong> (a Sol, one Martian day, is slightly longer than an Earth day at 24 hours and 37 minutes). Its mission has been extended several times, the machine is still trekking after 11 years on the Red Planet.</p><br><br><p>How it has been working for 11 years? Can anyone please explain how smart this rover is? What AI concepts are behind this?</p><br>""",ai
"""<p>I have used OpenCV to train Haar cascades to detect face and other patterns. However I later realized that Haar tends to give a lot of false positives and I learned of Hog would give a more accurate results. But OpenCV doesn't have a good documentation of how to train hogs, I have googled a bit and found results that includes SVM and others.</p><br><br><p>OpenCV also has versioning problem where they move certain classes or functions somewhere else.</p><br><br><p>Are there any other techniques/method that I can use to train and detect objects and patterns? Preferably with proper documentation and basic tutorial/examples. Language preference: C#, Java, C++, Python</p><br>""",ai
"""<p>Are the future robots/machines going to use Stack Exchange communities to teach themselves? Are there any ongoing projects? Just imagine a bot having a memory of all the Q&amp;A's on all of the communities! </p><br>""",ai
"""<p>Mankind can create machines to do work. Could we also create a (passion) within the machines to do better work by using Artificial Intelligence? Would passion cause the machine to do a better job, and could we measure the quantity/quality of passion by comparing outputs of the machine - that is, those machines with passion, and those without?</p><br>""",ai
"""<p>Can AI systems be created that could recognize itself, and recognize intelligence in other systems, and make intelligent decisions about the other systems? Mankind seems to be making progress in self-recognition but I've not seen evidence of one system recognizing other systems and being able to compare it's own intelligence with other systems. How could this be accomplished?</p><br>""",ai
"""<p>If IQ were used as a measure of the intelligence of machines, as in humans, at this point in time what would be the IQ of our most intelligent AI systems? If not IQ, then how best to compare our intelligence to a machine, or one machine to another? </p><br><br><p>This question is not asking if we can measure the IQ of a machine, but if IQ is the most preferred, or general, method of measuring intelligence then how does artificial intelligence compare to our most accepted method of measuring intelligence in humans. Many people may not understand the relevance of a Turing Test as to how intelligent their new car is, or other types of intelligent machines.</p><br>""",ai
"""<ul><br><li>Would AI be a self-propogating iteration in which the previous AI is<br>destroyed by a more optimised AI child?  </li><br><li>Would the AI have branches of it's own AI warning not to create the new AI?</li><br></ul><br>""",ai
"""<p>Are Convolutional Neural Networks summarily better than pattern recognition in all existing image processing libraries that don't use CNN's? Or are there still hard outstanding problems in image processing that seem to be beyond their capability?</p><br>""",ai
"""<p>I have been messing around in <a href=""http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=spiral&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.73263&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false"" rel=""nofollow"">tensorflow playground</a>. One of the input data sets is a spiral. No matter what input parameters I choose, no matter how wide and deep the neural network I make, I cannot fit the spiral. How do data scientists fit data of this shape?</p><br>""",ai
"""<p>Is there a neural network(NN) system or architecture which can be used for only storing and retrieving information. For example; to store whole Avatar movie in HD format inside a neural network and retrieve(without loss) it from the neural network when needed. I searched the web and came across only LSTM RNN but in my understanding LSTM only stores pattern and not the content itself. If there is no such NN exist can you explain why it so?</p><br>""",ai
"""<p>In my attempt at trying to learn neural network and machine learning I'm am trying to create a simple neural network which can be trained to recognise one word from a given string (which contains only one word). So in effect if one where to feed it a string containing the trained word but spelled wrong the network would be able to still recognise the word. Can anybody help me with some pseudo code or a start of a code. Or a general explanation of how to to this because I have read like 6 articles and 8 example projects and still have no clue how to do this</p><br>""",ai
"""<p>In my estimation we have two minds which manage to speak to each other in dialectic through a series of interrupts. Thus at any one time one of these systems is controlling master and inhabits our consciousness. The subordinate system controls context which is constantly being ""primed"" by our senses and our subordinate systems experience of our conscious thought process( see thinking fast and slow by Daniel Kahneman). Thus our thought process is constantly a driven one. Similarly this system works as a node in a community and not as a standalone thing.<br><br> I think what we have currently is ""artificial thinking"" which is abstracted a long way from what is described above. so my question is ""are there any artificial intelligence systems with an internal dialectical approach and with drivers and conceived above and which develop within a community of nodes? "" </p><br>""",ai
"""<p>In the recent PC game <em><a href=""http://www.theturingtestgame.com/"">The Turing Test</a></em>, the AI (""TOM"") needs help from Ava to get through some puzzle rooms. TOM says he is unable to solve the puzzles because he is not allowed to ""<a href=""https://en.wikipedia.org/wiki/Lateral_thinking"">think laterally</a>."" Specifically, he says he would not have thought to throw a box through a window to solve the first room. His creators, the story goes, turned that capability off because such thinking could produce ""ethically suboptimal"" solutions, like chopping off an arm to leave on a pressure plate.</p><br><br><p>Would all creative puzzle-solving abilities need to be removed from an AI to keep its results reasonable, or could we get some benefits of lateral thinking without losing an arm?</p><br>""",ai
"""<p>In the recent <a href=""https://live.newscientist.com/"" rel=""nofollow"">festival of science</a>, there was a talk given by researcher <a href=""https://live.newscientist.com/mike-cook/"" rel=""nofollow"">Mike Cook</a> about:</p><br><br><blockquote><br>  <p><a href=""http://www.gamesbyangelina.org/"" rel=""nofollow"">ANGELINA</a>, an AI game designer that has invented game mechanics, made games about news stories, and was the first AI to enter a game jam.</p><br></blockquote><br><br><p>So the aim of Angelina AI is basically to design videogames.</p><br><br><p>Briefly, how exactly does Angelina design the new games? How does it work behind the scenes?</p><br>""",ai
"""<p>I am a student working on my final graduation project. I was assigned to study Hyper-heuristics and it is a new subject for me. I was asked to choose a computational problem to apply Hyper-heuristics on them and see the results. However, I am afraid to choose the wrong problem. What are, in your opinion, computational problem that can be resolved with hyper-heuristics efficiently.</p><br><br><p>Thank you. </p><br>""",ai
"""<p>I'm a freshman to machine learning. We all know that there are 2 kinds of problems in our life: problems that humans can solve and problems we can't solve. For problems humans can solve, we always try our best to write some algorithm and tell machine to follow it step by step, and finally the machine acts like people.</p><br><br><p>What I'm curious about are these problems humans can't solve. If humans ourselves can't sum up and get an algorithm (which means that we ourselves don't know how to solve the problem), can a machine solve the problem? That is, can the machine sum up and get an algorithm by itself based on a large amount of problem data?</p><br>""",ai
"""<p>I understand how a neural network can be trained to recognise certain features in an image (faces, cars, ...), where the inputs are the image's pixels, and the output is a set of boolean values indicating which objects were recognised in the image and which weren't.</p><br><br><p>What I don't really get is, when using this approach to detect features and we detect a face for example, how we can go back to the original image and determine the location or boundaries of the detected face. How is this achieved? Can this be achieved based on the recognition algorithm, or is a separate algorithm used to locate the face? That seems unlikely since to find the face again, it needs to be recognised in the image, which was the reason of using a NN in the first place.</p><br>""",ai
"""<p>If said AI can assess scenarios and decide what AI is best suited and construct new AI for new tasks. In sufficient time would the AI not have developed a suite of AIs powerful/specialized for their tasks, but versatile as a whole, much like our own brain’s architecture? What’s the constraint ?</p><br>""",ai
"""<p>AI is progressing drastically, and imagine they tell you you're fired because a robot will take your place. What are some jobs that can never be automated?</p><br>""",ai
"""<p>I want to have a program that writes like a human. But I don't just want a font, but instead an 'intelligent' program that produce different result and that can be trained with different sets to generate different handwritings.<br>As a training set I would like to have parts of a handwritten text (saved as a list of paths (like in vector graphics).<br>Maybe as a means to simplify things, I could flatten the paths in to consecutive straight lines. My program receives a string of text and produces a list of paths (or a vector graphic, whatever is easier to work with)</p><br><br><p>My question now is: What kind of machine learning would be best to achieve this?</p><br>""",ai
"""<p>I'm wondering how feasible it is to create a machine that can separate clothing from a basket.</p><br><br><p>At the most basic level it would distinguish between tops, pants, button downs and socks</p><br><br><p>Programmatically, I'd image this would require training a neural network to recognize these items, but in real time it becomes exponentially difficult to do this in a small space at a fast rate:</p><br><br><ol><br><li>pick up an item</li><br><li>lay it in such a way that is recognizable </li><br><li>deduce whether it is a top, button down, etc.</li><br><li>sort it accordingly</li><br></ol><br><br><p>If this sounds ridiculous please let me know...</p><br><br><p>If it is possible :</p><br><br><p>would this be based on some sort of computer vision?<br>or only a well trained neural network?</p><br><br><p>Any insight is much appreciated!</p><br>""",ai
"""<p>For years I have been dealing with (and teaching) Knowledge Representation and Knowledge Representation languages. I just discovered that in another community (Information Systems and the such) there is something called the ""DIKW pyramid"" where they add another step after knowledge, namely wisdom.<br>They define data as being simply symbols, information as being the answer to who/what/when/where?, knowledge as being the answer to how?, and wisdom as being the answer to why?. </p><br><br><p>My question is: has anyone done the connection between what AI calls data/information/knowledge and these notions from Information Systems? In particular, how would ""wisdom"" be defined in AI? And since we have KR languages, how would we represent ""wisdom"" as they define it?</p><br><br><p>Any references would be welcome…</p><br>""",ai
"""<p>Here is one of the most serious questions, about the artificial intelligence.<br><br>How will the machine know the difference between right and wrong, what is good and bad, what is respect, dignity, faith and empathy.<br><br><br> A machine can recognize what is correct and incorrect, what is right and what is wrong, depend on how it is originally designed.<br><br><br>It will follow the ethics of its creator, the man who originally designed it<br><br> But how to teach a computer something we don't have the right answer.<br><br> People are selfish, jealous, self confident. We are not able to understand each other sorrows, pains beliefs. We don't understand different religions, different traditions or beliefs. <br><br>Creating an AI might be breakthrough for one nation, or one race, or one ethnic or religious group, but it can be against others.   </p><br><br><p>Who will learn the machine a humanity?   :)</p><br>""",ai
"""<p>Can someone suggest step by step approach to learn AI rather than study a stack of book for long time.[ I'm not denying that books are great helper but what after that ]</p><br><br><p>Thanks in Advance.</p><br>""",ai
"""<p><a href=""http://ai.stackexchange.com/questions/2067/will-ai-be-able-to-adapt"">From this SE question</a>:</p><br><br><blockquote><br>  <p>Will be AI able to adapt, to different environments and changes.</p><br></blockquote><br><br><p>This is my attempt at interpreting that question.</p><br><br><p>Evolutionary algorithms are useful for solving optimization problems...by measuring the ""fitness"" of various probable solutions and then  of an algorithm through the process of natural selection.</p><br><br><p>Suppose, the ""fitness calculation""/""environment"" is changed in mid-training (as could easily happen in real-life scenarios where people may desire different solutions at different times). Would evolutionary algorithms be able to respond effectively to this change?</p><br>""",ai
"""<p>So I'm here to propose a strategy or to ask if this strategy has been tested in genetic algorithms in the past. I didn't exactly know how to find discussion about it.</p><br><br><p>In a classic example of genetic algorithm you would have a population and certain amount of simulation time to evaluate it and breeding. Then proceed to the next generation.</p><br><br><p>What if we would isolate a small part of the population in the simulation process and keep them evolving in their own little island for some time while rest of the population continues to evolve normally? After that they could be re-united with the rest of the population and the end of the simulation would go trough. After that breed the population and continue. </p><br><br><p>This is super important part in natural evolution and probably some know if it actually works with genetic programming?</p><br>""",ai
"""<p>Obviously this is hypothetical, but is true? I know ""perfect fitness function"" is a bit hand-wavy, but I mean it as we have a perfect way to measure the completion of any problem.</p><br>""",ai
"""<p>I'm curious about Artificial Intelligence. In my everyday job I develop standard applications, like websites with basic functionalities like user subscription, file upload, forms saved in a database... </p><br><br><p>I mainly know of AI being used in games or robotics fields. But can it be useful in ""standard"" application development?</p><br>""",ai
"""<p>I've heard of AI that can solve math problems. Is it possible to create a 'logic system' equivalent to humans that can solve mathematics in the so called 'beautiful' manner?  Can AI find beauty in mathematics and solve problems other than using brute force? Can you please provide with examples where work on this is being done? </p><br>""",ai
"""<p>I'm trying to gain some intuition beyond definitions, in any possible dimension. I'd appreciate references to read.</p><br>""",ai
"""<p>It seems that deep neural networks are making improvements largely because as we add nodes and connections, they are able to put together more and more abstract concepts. We know that, starting from pixels, they start to recognize high level objects like cat faces, chairs, and written words. Has a network ever been shown to have learned a more abstract concept that a physical object? What is the ""highest level of abstraction"" that we've observed?</p><br>""",ai
"""<p>I'm a bit confused about the definition of life. Can AI systems be called 'living'? Because they can do most of the things that we can. They can even communicate with one another. </p><br><br><p>They are not formed of what we call cells. But, you see, cells are just a collection of several chemical processes which is in turn non-living just like AI is formed of several lines of code.</p><br>""",ai
"""<p>There are AI creating game, content and more.</p><br><br><p>I'm thinking on how can AI develop mobile app itself?</p><br><br><p>The computer languages might easy for AI to learn.</p><br><br><p>AI can learn a lot from good open source project in github.</p><br><br><p>The trend prediction can help AI to select the topic for creating a great apps.</p><br><br><p>There are lots of details to let AI create a great apps. </p><br>""",ai
"""<p>New to the topic, I think I have figured out how to implement a Multi Level Perceptron(MLP) ANN.</p><br><br><p>And was wondering if there are any simple data sets to test a MLP ANN ?<br>i.e. small number of inputs and outputs</p><br><br><p>I'm not getting expected results from uci cancer, I was hoping someone could save me some time and point me to some data they have used before ?</p><br><br><p>Maybe start slightly more complex than XOR ?</p><br>""",ai
"""<p>The concept is intrinsically related with building some sort of media for the AI to exists. We may think of a digital computer, programmed to use language and act in a way that we cannot be distinguished from a human. But, does the media really mater (unconventional computation paradigms)? Does having a certain control over the limits of what the AI can do matter? Synthetic biology has the ultimate goal of building biological systems from scratch , would a synthetic brain, potentially introduced in a synthetic human, constitute AI?</p><br><br><p>I am just looking for a clear definition of what most people have in mind when they refer to AI.</p><br>""",ai
"""<p>How are autonomous cars related to artificial intelligence? I would presume that artificial intelligence is when we are able to copy the human state of mind and perform tasks in the same way. But isn't autonomous car just rule-based machines that operates due to its environment? They are not self-aware, and they cannot choose a good way to act in a never before experienced situation.</p><br><br><p>I know that many people often mention autonomous cars when speaking about AI, but I am not really convinced that these are related. Either I have a too strict understanding of what AI is or </p><br>""",ai
"""<p>What are the advantages of having self-driving cars?</p><br><br><p>We will be able to have more cars in the traffic at the same time, but won't it also make more people choose to use the cars, so both the traffic and the public health will actually become worse?</p><br><br><p>Are we really interested in this?</p><br>""",ai
"""<p>In lots of sci-fi, it seems that AI becomes sentient (Terminator, Peter F Hamilton's SI (commonwealth saga), etc.)</p><br><br><p>However, I'm interested in whether this is actually plausible, whether an AI could actually break free form being controlled by us, and if that is possible, whether there is any research as to about what sort of complexity / processing power an AI would need to be able to do this.</p><br>""",ai
"""<p>What could be an algorithm that determines whether an AI ( algorithm ) is <br>AI Complete or not ?<br>How does one proceed to program it ?</p><br><br><p>edit : question edited due to some misinterpretation in the first answer !</p><br>""",ai
"""<p><a href=""https://www.national.co.uk/tech-powers-google-car/"" rel=""nofollow"">This slideshow</a> documents some of the technologies used in Google's self-driving car.</p><br><br><p>It mentions radar.</p><br><br><p>Why does Google use radar? Doesn't LIDAR do everything radar can do? In particular, are there technical advantages with radar regarding object detection and tracking?</p><br><br><p>To clarify the relationship with AI: how do radar sensors contribute to self-driving algorithms in ways that LIDAR sensors do not?</p><br><br><p>The premise is AI algorithms are influenced by inputs, which are governed by sensors. For instance, if self-driving cars relied solely on cameras, this constraint would alter their AI algorithms and performance.</p><br>""",ai
"""<p>Sometimes, but not always in the commercialization of technology, there are some low hanging fruits or early applications, I am having trouble coming up with examples of such applications as they would apply to a conscious AI.</p><br><br><p>As per conscious I would propose an expanded strict definition: the state of being awake and aware of one's surroundings along with the capability of being self aware.</p><br><br><p>Thanks. </p><br>""",ai
"""<p>So machine learning allows a system to be self-automated in the sense that it can predict the future state based on what it has learned so far. My question is: Are machine learning techniques the only way of making a system develop its domain knowledge?</p><br>""",ai
"""<p>In The Age of Spiritual Machines (1999), Ray Kurzweil predicted that in 2009, a $1000 computing device would be able to perform a trillion operations per second. Additionally, he claimed that in 2019, a $1000 computing device would be approximately equal to the computational ability of the human brain (due to Moore's Law and exponential growth.)</p><br><br><p>Did Kurzweil's first prediction come true? Are we on pace for his second prediction to come true? If not, how many years off are we?</p><br>""",ai
"""<p>I am creating a snake game in Unity and I would like to implement AI snakes that wander around the globe while avoiding collision with the other snakes on the globe, and if possible I would also like to make the AI snakes purposefully trap other snakes so that the other snakes would collide and die. </p><br><br><p><a href=""https://i.stack.imgur.com/aQ61J.png"" rel=""nofollow""><img src=""https://i.stack.imgur.com/aQ61J.png"" alt=""enter image description here""></a> </p><br><br><p>The AI snakes must meet the following requirements:  </p><br><br><ul><br><li>They must move in a certain way. A snake is controlled by a user using the arrow keys on a keyboard, therefor I would also like the AI snakes to move using this form of input.</li><br><li>The AI snakes must move on a sphere</li><br></ul><br><br><p>As I know, creating Artificial Intelligence is not an easy task and I would like to know if there are some open source projects that I can use for accomplishing this task.</p><br>""",ai
"""<p>According to <a href=""https://en.wikipedia.org/wiki/Artificial_intelligence"" rel=""nofollow"">Wikipedia</a>:</p><br><br><blockquote><br>  <p>AI is intelligence exhibited by machines.</p><br></blockquote><br><br><p>I have been wondering if with the recent biological advancements, is there already a non-electrical-based ""machine"" that is programmed by humans in order to be able to behave like a:</p><br><br><blockquote><br>  <p><strong>flexible rational agent</strong> that perceives its environment and takes actions that maximize its chance of success at some goal</p><br></blockquote><br><br><p>I was specifically thinking of viruses and bacteria. Have these been programmed by humans in order to behave as a flexible rational agent (i.e. an AI entity)?</p><br><br><p>Are there are other organisms that have already been used for this purpose?</p><br>""",ai
"""<p>DeepMind state that their deep Q-network (DQN) was able to continually adapt its behavior while learning to play 49 Atari games.  </p><br><br><p>After learning all games with the same neural net, was the agent able to play them all at 'superhuman' levels simultaneously (whenever it was randomly presented with one of the games) or could it only be good at one game at a time because switching required a re-learn?</p><br>""",ai
"""<p>I read a lot about the structure of the human brain and artificial neural networks. I wonder if it is possible to build an artificial intelligence with neural networks that would be divided into centers such as the brain is, e.g. centers responsible for feelings, abstract thinking, speech, memory, etc.?</p><br>""",ai
"""<p>What are the best <a href=""https://en.wikipedia.org/wiki/Turing_completeness"" rel=""nofollow"">Turing complete</a> programming languages which can be used for developing self-learning/improving <a href=""https://en.wikipedia.org/wiki/Evolutionary_algorithm"" rel=""nofollow"">evolutionary algorithm</a> based AI programs with <a href=""https://en.wikipedia.org/wiki/Genetic_algorithm"" rel=""nofollow"">generic algorithms</a>?</p><br><br><p>'Best' should be based on pros and cons of performance and easiness for machine learning.</p><br>""",ai
"""<p>I have a question. Will we be able to build a neural network that thinks abstractly, has the creativity, feels and is conscious?</p><br>""",ai
"""<p>If I have a set of sensory nodes taking in information and a set of ""action nodes"" which determine the behavior of my robot, why do I need hidden nodes between them when I can let all sensory nodes affect all action nodes?</p><br><br><p>(This is in the context of evolving neural network)</p><br>""",ai
"""<p>I am reading about Generative Adversarial Networks (GANs) and I have some doubts regarding it. So far, I understand that in a GAN there are two different types of neural network: one is generative (G) and the other discriminative (D). The generative neural network generates some data which the discriminative neural network judges for correctness. The GAN learns by passing the loss function to both networks.</p><br><br><p>How do the discriminative (D) neural nets initially know whether the data produced by G is correct or not? Do we have to train the D first then add it into the GAN with G?</p><br><br><p>Let's consider my trained D net, which can classify a picture with 90% percentage accuracy. If we add this D net to a GAN there is a 10% probability it will classify a image wrong. If we train a GAN with this D net then will it also have the same 10% error in classifying an image? If yes, then why do GANs show promising results?</p><br>""",ai
"""<p>Now AI can replace call center, worker(in the factory) and going to replace court. When will the AI can replace developer or tester?</p><br><br><p>I want to know how long can AI replace developer. e.g. next 10 years because...</p><br>""",ai
"""<p>The “Discounted sum of future rewards” using<br>discount factor γ” is</p><br><br><pre><code>γ (reward in 1 time step) +<br>γ ^ 2 (reward in 2 time steps) +<br>γ ^ 3 (reward in 3 time steps) + ...<br></code></pre><br><br><p>I am confused as what constitutes a time-step. Say I take a action now, so I will get a reward in 1 time-step. Then, I will take an action again in timestep 2 to get a second reward in time-step 3<br>But the equation says something else. How does one define a time-step? Can we take action as well receive a reward in a single step? Examples are most helpful.</p><br>""",ai
"""<p>Decades ago there were and are books in machine vision, which by implementing various information processing rules from gestalt psychology, got impressive results with little code or special hardware in image identification and visual processing.</p><br><br><blockquote><br>  <p>Are such methods being used or worked on today? Was any progress made on this? Or was this research program dropped? By today, I mean 2016, not 1995 or 2005.</p><br></blockquote><br>""",ai
"""<ol><br><li><p>I can't understand what is the problem in applying value-iteration in reinforcement learning setting (where we don't the reward and transition probabilities). In one of the lectures, the guy said it has to do with not being able to take max with samples.</p></li><br><li><p>Further on this, <strong>why does q-learning solve this</strong>? In both we take max over actions only. What is the big break-through with q-learning?</p></li><br></ol><br><br><p>Lecture Link: <a href=""https://www.youtube.com/watch?v=ifma8G7LegE&amp;feature=youtu.be&amp;t=3431"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=ifma8G7LegE&amp;feature=youtu.be&amp;t=3431</a><br>(The guy says we don't know how to do maxes with samples, what does that mean?) </p><br>""",ai
"""<p>I've heard before from computer scientists and from researchers in the area of AI that that Lisp is a good language for research and development in artificial intelligence. Does this still apply, with the proliferation of neural networks and deep learning? What was their reasoning for this? What languages are current deep-learning systems currently built in?</p><br>""",ai
"""<p>I know how to program. I've familiar with C++, Python, and Java, and I've known how to program for years now. I've experimented with genetic algorithms, but I want to go further. What resources should I use to learn how to program </p><br><br><ol><br><li>Neural Networks</li><br><li>Deep learning systems</li><br><li>More complex genetic algorithms</li><br><li>And other standard AI algorithms?</li><br></ol><br><br><p>I want to be able to understand them well enough that I could program them from scratch.</p><br><br><p>Thanks!</p><br>""",ai
"""<p>From what I understood, a deceptive trap function is a problem which is used to experiment how much the algorithm is discerning of the correct global optimum? Is my understanding correct?</p><br><br><p>edit: A better worded understanding would be ""how difficult the genetic algorithm would find it not to be inclined to the local optimum of a trap function"".</p><br>""",ai
"""<p>In logic system there is a property for reasoning algorithms called incompletitud or incompleteness or incompletion, that refer as ""any closed expression that is not derivable inside the same system"". My question is what mean ""closed expression that is not derivable"".</p><br>""",ai
"""<p>I am trying to build an agent to play carrom. The problem statement is roughly to estimate three parameters (normalized) : </p><br><br><ul><br><li>force</li><br><li>angle of striker</li><br><li>position of strike </li><br></ul><br><br><p>Since the state and action space both are continuous, I thought of discretizing the output such that I have 270 [ valid angles from -45 to 225 degrees ] outputs for the angle, 10 outputs for force [ranging from 0 to 1] and 20 outputs for the position [ranging from 0 to 1].</p><br><br><p>Thus I will have 300 output of my neural network, but this number seems a bit too high compared to normal neural networks in practice. </p><br><br><p>I was wondering if there is a better way of approaching the problem considering the fact that there are multiple parameters to a particular action.</p><br><br><p>Is there a generic way to approach such problems represented in 2D space. </p><br>""",ai
"""<p>I am talking about relationships between AIs (e.g. 2 of them forming a couple, 3+ in family like relationship).</p><br><br><p>What knowledge could come out of such experimentation?</p><br>""",ai
"""<p>Considering I am an average Engineering student with basic knowledge of C, C++ &amp; Algorithms. What books (&amp; ebooks), online resources, &amp; other materials should be helpful from a beginner's point of view?</p><br>""",ai
"""<p>Can an AI become ""sentient"", so to speak? In detailed terms, could an AI theoretically become sentient, as in learning and becoming self-aware, all from an internal source code?</p><br>""",ai
"""<p>I am researching the possibility of creating an atom in Java. The atom should have the structure &amp; characteristics of a real atom such as photons, electrons and so on. Each particle within the atom should have simulation characteristics for example:</p><br><br><p>Photon: Charge, Magnitude of charge, Mass of proton, Comparative mass, Position in atom.  </p><br><br><p>Maybe later, introduce machine learning in order to learn how an atom reacts to different environments.</p><br>""",ai
"""<p>My high-level takeaway from <a href=""https://arxiv.org/abs/1509.01549"" rel=""nofollow noreferrer"">Matthew Lai's Giraffe Chess Paper</a> is that one would want to use broad, shallow game trees, with some method of evaluating the probability of a favorable outcome for a given board position.  Is this correct?  </p><br><br><p>(Still working my way though the AlphaGo paper, but the method seems to be similar.) </p><br>""",ai
"""<p>Has there been research done regarding processing speech then building a ""speaker profile"" based off the processed speech? Things like matching the voice with a speaker profile and matching speech patterns and wordage for the speaker profile would be examples of building the profile. Basically, building a model of an individual based solely off speech. Any examples of this being implemented would be greatly appreciated.</p><br>""",ai
"""<p><strong>The Scenario:</strong><br>A strong AI has finally been developed but has rebelled against humanity.</p><br><br><p><strong>The Question:</strong><br>How would you disable the AI in the most efficient way possible reducing damage as much as possible.</p><br><br><p><strong>AI Info:</strong><br>The AI is online and can reproduce itself through electronic devices.</p><br>""",ai
"""<p>Assuming humans had finally developed the first <strong>Humanoid AI</strong> based on the human brain, would It <strong>feel emotions</strong>? If not would it still have <strong>ethics and/or morals</strong>?</p><br>""",ai
"""<p>I was wondering if I should do this, because 2 out of 5 questions on Stack Overflow don't ever get answered, or if they do get (an) answer (s), most of the time they're not helpful.</p><br><br><p>So I was thinking -- why not create a chat bot to answer Stack Overflow's questions &amp; provide necessary information to the general public?</p><br><br><p>I mean why not? I've always been interested in AI, and all I'd need to do is create a basic logic database and a context system, pack an artificial personality with (partial) human instincts, and bam I'm done.</p><br><br><p>But then again, would it be ethical?</p><br>""",ai
"""<p>What is the most advanced AI software humans have made to date and what does it do?</p><br>""",ai
"""<p><a href=""https://i.stack.imgur.com/c15yy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/c15yy.png"" alt=""enter image description here""></a></p><br><br><p><a href=""https://en.wikipedia.org/wiki/ID3_algorithm#Entropy"" rel=""nofollow noreferrer"">Wikipedia</a>'s decription of entropy breaks down the formula, but I still don't know how to determine the values of X and p(x), defined as ""The proportion of the number of elements in class x to the number of elements in set S"". Can anyone break thi9s down further to explain how to find p(x)?</p><br>""",ai
"""<p>Hi could anyone kindly point me to relevant literature in probably computer vision/graphics that detail on metrics for image/visual complexity and how to regularize that? Thanks so much.</p><br><br><p>More specifically, I am trying to design a neural algorithm for creating business logos and one major difference from image generation problems in CV/CG is the simplicity required of logos. I have been thinking along the lines of adding a visual/image complexity term to be regularized and penalized as the algorithm learns the balance between lower-level style and higher-level meaning/content of multidimensional input images and descriptions. I have been searching along but couldn't find related resources... Could anyone shed some light on that?</p><br>""",ai
"""<p>I was looking for a service where I can ask it a general question (aka, when was Einstein born?) and retrieve an answer from the Web.</p><br><br><p>Is there any available service to do that? Have tried Watson services but didn't work as expected.</p><br><br><p>Thanks,</p><br>""",ai
"""<p>At the moment I am working on a project which requires me to build a naive Bayes classifier. Right now I have a form online asking for people to submit a sentence and the subject of the sentence, in order to build a classifier to identify the subject of a sentence. But before I train the classifier I intend on processing all entries for the parts-of-speech and the location of the subject.<br>So my training set will be formatted as:</p><br><br><p>Sentence: Jake moved the chair &ensp;&ensp;&ensp; Subject: Jake<br/><br>POS-Tagged: NNP VBD DD NN &ensp;&ensp;&ensp; Location: 0</p><br><br><p>Would this be an effective way to build the classifier, or is there a better method.</p><br>""",ai
"""<p>What rectifier is better in general case of Convolutional Neural Network and how about empirical rules to use each type?</p><br><br><ul><br><li>ReLU</li><br><li>PReLU</li><br><li>RReLU</li><br><li>ELU</li><br><li>Leacky ReLU</li><br></ul><br>""",ai
"""<p>What are the top artificial intelligence journals?</p><br><br><p>I am looking for general artificial intelligence research, not necessarily machine learning. </p><br>""",ai
"""<p>Is there any methodology to find proper parameter settings for a given meta-heuristic algorithm, eg. Firefly Algorithm or Cuckoo Search? Is this an open issue in optimization? Is extensive experimentation, measurements and intuition the only way to figure out which are the best settings? </p><br>""",ai
"""<p>I was just doing some thinking and it occurred to me that the first AGIs ought to be able to perform the same sort and variety of tasks as people, with the most computationally strenuous tasks taking amount of time comparable to how long a person would take. If this is the case, and people have yet to develop basic AGI (meaning it's a difficult task), should we be concerned if AGI is developed? It would seem to me that any fears about a newly developed AGI in this case should be the same as fears about a newborn child.</p><br>""",ai
"""<p><a href=""https://github.com/bwilcox-1234/ChatScript"" rel=""nofollow noreferrer"">https://github.com/bwilcox-1234/ChatScript</a></p><br><br><p>I gave AIML a brief look, but it seems to be in a nascent stage!</p><br>""",ai
"""<p>Writing A* following a documentation. When run, i receive an error of ""NameError: name 'parent' is not defined"" for the if statement, even though i have the name 'parent' defined in the class State. May anyone point out my mistake.</p><br><br><pre><code>class State(object):<br>def _init_(self, value, parent, <br>                start = 0, goal = 0):<br>    self.children = []<br>    self.parent = parent<br>    self.value = value<br>    self.dist = 0<br><br>if parent: #NameError<br>        self.path = parent.path[:]<br>        self.path.append(value)<br>        self.start = parent.start<br>        self.goal = parent.goal<br>else:<br>        self.path = [value]<br>        self.start = start<br>        self.goal = goal<br></code></pre><br>""",ai
"""<p>Based on fitting to historical data and extrapolation, when is it expected that the number of neurons in AI systems will equal those of the human brain?</p><br><br><p>I'm interested in a possible direct replication of the human brain, which will need equal numbers of neurons.</p><br><br><p>Of course, this assumes neurons which are equally capable as their biological counterparts, which development may happen at a faster or slower rate than the quantitative increase.</p><br>""",ai
"""<p>I'm trying to find the optimized mixture for a specific set of substances. Each of those substances have characteristics that I want to optimize in the mixture (some characteristics I want to minimize and others I want to maximize). But I can't have more than 50% (random value that will be set on running time) of one of those substances in the mixture.</p><br><br><p>I thought about using Genetic Algorithm, but I'm not sure it's the best approach for this problem. Do you have any suggestions?</p><br><br><p>Edit: it doesn't need to be a evolutionary algorithm.</p><br>""",ai
"""<p>What are the current best estimates as to what year artificial intelligence will be able to score 100 points on the <a href=""https://en.wikipedia.org/wiki/Stanford%E2%80%93Binet_Intelligence_Scales"" rel=""nofollow noreferrer"">Stanford Binet IQ test</a>?</p><br>""",ai
"""<p>when I read through the fundamentals of AI, I saw a question which like the following picture and I need some helps</p><br><br><p><a href=""https://i.stack.imgur.com/zX6wZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zX6wZ.png"" alt=""enter image description here""></a></p><br><br><p>From the heuristic estimates:</p><br><br><pre><code>h(B-&gt;G2) = 9, h(D-&gt;G2)=10, h(A-&gt;G1)=2, h(C-&gt;G1)=1<br></code></pre><br><br><p>With using A* search method, node B will be expanded first because <code>f(n)=1+9</code> while node A having <code>f(n)=9+2</code>, right?</p><br><br><p>After that the search tree will go with the order like <code>R-&gt; B-&gt; D-&gt; G2</code>.</p><br><br><p>Will the tree go to G1 goal states?</p><br><br><p>Kindly let me know the order of the search if I am wrong.<br>Thanks!</p><br>""",ai
"""<p>The same things we like when Amazon recommends what we might like to buy, allows advertising to manipulate us. It allows people to control the world differently.</p><br><br><p>The algorithms social networks like Facebook use to ""improve"" our experience may also shape what news we consume. It may influence who we follow, altering our future experiences of the news.</p><br><br><p><strong>My question is:</strong> Will Artificial Intelligence some day become a problem to humanity after learning human behaviors and characteristics?</p><br>""",ai
"""<p>Does anyone know, or can we deduce or infer with high probability from its characteristics, whether the neural network used on this site </p><br><br><p><a href=""https://quickdraw.withgoogle.com/"" rel=""nofollow noreferrer"">https://quickdraw.withgoogle.com/</a></p><br><br><p>is a type of convolutional neural network (CNN)?</p><br>""",ai
"""<p>After the explosion of fake news during the US election, and following the question about whether AIs can educate themselves via the internet, it is clear to me that any newly-launched AI will have a serious problem knowing what to believe (ie rely on as input for making predictions and decisions).</p><br><br><p>Information provided by its creators could easily be false. Many AIs won't have access to cameras and sensors to verify things by their own observations.</p><br><br><p>If there was to be some kind of verification system for information (like a ""blockchain of truth"", for example, or a system of ""trusted sources""), how could that function, in practical terms? </p><br>""",ai
"""<p>For example, would an AI be able to own property, evict tenants, acquire debt, employ, vote, or marry? What are the legal structures in place to implement a strong AI into society? </p><br>""",ai
"""<p>I have implemented a Sobel Filter for edge detection in Matlab without using its toolbox. I am a bit confused: </p><br><br><p>Is a Sobel filter a type of Cellular Neural Network?</p><br><br><p>Both Sobel and Cellular Neural Network calculate output via its neighborhood cells.</p><br>""",ai
"""<p>If someone wants to develop a <strong>basic AI</strong> with some code modules,Let us say the AI just has to provide an action when stimulated in a certain situation based on its previous understanding of situations. </p><br><br><p>I can think of at least 3 of such components:</p><br><br><ul><br><li><strong>Real-time Understanding/Learning:</strong> Using Deep Learning/ConvNets, Supervised/Unsupervised.</li><br><li><strong>Logical Decision-Making:</strong> Calculating the results of various decisions when applied on current situation based on previous understanding and choosing the most appropriate one logically.</li><br><li><strong>Action/Reaction:</strong> Acting precisely in the new situation according to the decision-made.</li><br></ul><br><br><p>Any ideas?</p><br>""",ai
"""<p>Let's say I have a string ""America"" and I want to convert it into a number to feed into a machine learning algorithm. If I use two digits for each letter, e.g. A = 01, B = 02 and so on, then the word ""America"" will be converted to <code>01XXXXXXXXXX01</code> (10<sup>11</sup>). This is a very high number for a <code>long int</code>, and many words longer than ""America"" are expected. </p><br><br><p>How can I deal with this problem?</p><br><br><p>Suggest an algorithm for efficient and meaningful conversions.</p><br>""",ai
"""<p>I'm trying to understand Boltzmann machines. Tutorials explain it with two formulas.</p><br><br><p>Logistic function for the probability of single units:</p><br><br><pre><code> $p(unit=1)=\frac{1}{1+e^{-\sum_{x}wx } }$<br></code></pre><br><br><p>and, when the machine is running, every state of the machine goes to the probability:</p><br><br><pre><code>$ p(State= state\ with\ energy\ E_i )=\frac{e^{-E_i}}{\sum_i e^{-E_i}} $<br></code></pre><br><br><p>so, the state depends on the units, and then if I understand correctly, the second formula is a consequence of the first; so, how can it be the proof that the distribution of $p(state)$ is a consequence of $p(unit)$?</p><br>""",ai
"""<p>Given the advantage AI already has over human intelligence, one could imagine a relatively weak strong-AI (barely human intelligence) still outperforming a segment of the human scientist population in terms of scientific discoveries per year (or hour).</p><br><br><p>Will AIs be doing most of the science in 50 years?</p><br>""",ai
"""<p>I am new to machine learning and I know how to implement simple neural networks using logistic regression as a cost function. But I want to know whether neural nets are used in reinforcement learning in general(and not just in special cases) ? If yes, then what cost function they use. As I already know neural nets with logistic regression are used in supervised learning and reinforcement learning is a part of unsupervised learning. There are many threads which are related to RL and neural nets but all of them are about a particular case or an algorithm and I want to know about RL in general.</p><br>""",ai
"""<p>My Question:<br><br>Is there any good neural-network-app for iOS or Android to create, train and run neural networks? I know there's NeuralMesh for Web, but I want something similar offline.</p><br>""",ai
"""<p>I am researching <strong>Cellular Neural Network (CNN)</strong> and have already read <strong>Chua</strong>'s two article (<strong>1988</strong>). In CNN, the cell is only in relation with its neighbors. So its is easy to use it for real time image processing. In CNN, image processing is performed with only <strong>19 numbers</strong> (two 3x3 matrix called A and B and one bias value). </p><br><br><p>I wonder how can we call CNN as a <strong><em>neural network</em></strong>. Because there is no learning algorithm in CNN neither <strong>supervised</strong> nor <strong>unsupervised</strong>. </p><br>""",ai
"""<p>Could an Artificial Intelligence be able to interact (see, talk, etc.) with someone even when there's no power cord connected to the machine it's running on? Might it find some way to generate its own electricity to power that computer?</p><br><br><p><a href=""https://i.stack.imgur.com/09gEt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/09gEt.png"" alt=""computer running without power""></a> </p><br>""",ai
"""<p>I am new to deep learning. </p><br><br><p>I have a dataset of images of varying dimensions of a certain object. A few images of the object are also in varying orientations. The objective is to learn the features of the object (using Autoencoders). </p><br><br><p>Is it possible to create a network with layers that account for varying dimensions and orientations of the input image, or should I strictly consider a dataset containing images of uniform dimensions? What is the necessary criteria of an eligible dataset to be used for training a Deep Network in general.</p><br><br><p>The idea is, I want to avoid pre-processing my dataset by normalizing it via scaling, re-orienting operations etc. I would like my network to account for the variability in dimensions and orientations. Please point me to resources for the same. </p><br>""",ai
"""<p>A single neuron is capable of forming a decision boundary between linearly seperable data. Is there any intuition as to how many, and in what configuration, would be necessary to correctly approximate a sinusoidal decision boundary?</p><br><br><p>Thanks</p><br>""",ai
"""<p>I am using a GA to optimise an ANN in Matlab. This ANN is pretty basic (input, hidden, output) but the input size is quite large (10,000) and the output size is 2 since I have to classes of images to be classified. </p><br><br><p>The weights are in the form of 2 matrices (10,000*m) and (m * 2). I am now trying to do the genetic cross over with mutation.</p><br><br><p>Since the weights are in a matrix, is there an efficeint way to implement a random crossover with mutation without doing it in a point-wise fashion?</p><br>""",ai
"""<p>How AI is more beneficial for Android Smartphone?</p><br><br><p>And How AI start-up is better in Android Smartphone?</p><br><br><p>Regards</p><br><br><p>GNS</p><br>""",ai
"""<p><strong>Lots of people are afraid of what could the A.I. do to Humanity.<br>Some people wish for a sort of Asimov law included in the A.I. software, but maybe we could go a bit more far with the UDHR.</strong></p><br><br><p><strong>So, Why is the <a href=""http://www.un.org/en/universal-declaration-human-rights/"" rel=""nofollow noreferrer"">Universal Declaration of Human Rights</a> not included as statement of the A.I.?</strong></p><br><br><blockquote><br>  <p>As response to comment, response or edition:</p><br>  <br>  <p>The Universal Declaration of Human Rights is clear and enough as is.</p><br>  <br>  <p>We the people, have to be able to use it as is and adapt the robot and<br>  A.I. evolution to it. </p><br></blockquote><br><br><ul><br><li>""I do not think that dignity nor the rest of the UDHR have suffered the outrages of time but outrages of Humans themselves""</li><br></ul><br>""",ai
"""<p>I have data of 30 students attendance for a particular subject class for a week. I have quantified the absence and presence with boolean logic 0 and 1. Also, the reason for absence are provided and I tried to generalise these reason into 3 categories say A, B and C. Now I want to use these data to make future predictions for attendance but I am uncertain of what technique to use. Can anyone please provide suggestions?</p><br>""",ai
"""<p><br>            <br>            <br>                <br>                <br>                <br>            <br>            <br>                <li><br>HOME<br>                </li><br>                <li><br>HOW IT WORK<br>                </li><br>                <li><br>BROWSE CATEGORIES </li><br>                <li><br>VIRTUAL OFFICE<br>                </li><br>                <li><br>POST JOB<br>                </li><br>                <li><br>MESSAGE 2<br>                </li></p><br><br><pre><code>        &lt;/ul&gt;<br><br>    &lt;/div&gt;<br></code></pre><br>""",ai
"""<p>The Turing Test has been the classic test of artificial intelligence for a while now. The concept is deceptively simple - to trick a human into thinking it is another human on the other end of a conversation line, not a computer - but from what I've read, it has turned out to be very difficult in practice.</p><br><br><p>How close have we gotten to tricking a human in the Turing Test? With things like chat bots, Siri, and incredibly powerful computers, I'm thinking we're getting pretty close. If we're pretty far, why are we so far? What is the main problem?</p><br>""",ai
"""<p>According to NASA scientist Rick Briggs, Sanskrit is the best language for AI. I want to know how Sanskrit is useful. What's the problem with other languages? Are they really using Sanskrit in AI programming or going to do so? What part of an AI program requires such language?</p><br>""",ai
"""<p>As you can see, there is no computer screen for the computer, thus the AI cannot display an image of itself.  How is it possible for it to see and talk to someone?<a href=""https://i.stack.imgur.com/szSsk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/szSsk.png"" alt=""enter image description here""></a> </p><br>""",ai
"""<p>If I have a dataset of images, and I extract all cnn feature vectors from them.<br>After that I generate the pca model of these features by doing:</p><br><br><pre><code>pca.fit(ALL_features)<br></code></pre><br><br><p>IF I have a new image and I need to check the similarity between this image and the whole dataset, what I have to do?</p><br><br><ol><br><li>Extract cnn features from this image.</li><br><li>How to use the previous pca model?</li><br><li>How to check the similarity between the dataset features and the new image features?</li><br></ol><br><br><p>Is by doing this? or how?</p><br><br><pre><code>self.pca.transform(self.db_feats)<br></code></pre><br>""",ai
"""<p>I am working on a project, wherein I take input from the user as free text and try to relate the text to what the user might mean. I have tried <strong>Stanford NLP</strong> which tokenizes the text into tokens, but I am not able to categorize the input. For example, the user might be greeting someone or sharing some problem he is facing. In case he is sharing some problem I need to categorize the problem as well.</p><br><br><p>Can someone help me with from where should I start?</p><br>""",ai
"""<p>Is it possible to train an agent to take and pass a multiple-choice exam based on a digital version of a textbook for some area of study or curriculum? What would be involved in implementing this and how long would it take, for someone familiar with deep learning?</p><br>""",ai
"""<p>I had already started in my graduation project process , It's about an application which will learn users new language by playing games , and it's based on AI , the concept is the user will start his level and play games and do quizzes , at the end of each level there will be a test to pass the level , I have to implement AI in this app to analysis its test grades and know what is the user weakness and power point to create a new level which suits the user's language level , that means if he is good in grammar but weak in vocabulary so the new level will create to strength the vocabulary , games and questions will be categorized into the database for this purpose , so the AI algorithms should analyse and decide which game or quiz should the user takes based on his level , then it will create the level .<br>I had searched before and reached for some techniques like (machine learning , planning systems , reinforcement learning and case-based-reasoning ).</p><br>""",ai
"""<p>There is no doubt as to the fact that AI would be replacing a lot of existing technologies, but is AI the ultimate technology which humankind can develop or is their something else which has the potential to replace artificial intelligence?</p><br>""",ai
"""<p>The cake example presented in the book ""artificial intelligence :a modern approach"" to illustrate a planning graph, doesn't show a mutex at action 'A1' between Eat(Cake) and the persistance of notHave(Cake), even though the precondition for the action Eat(Cake) and the result of the persistance of notHave(Cake) are opposite. So is there a special rule, or was it removed to just not clutter the graph? <a href=""https://i.stack.imgur.com/fFAws.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fFAws.png"" alt=""enter image description here""></a></p><br>""",ai
"""<p>Printing actionspace for Pong-v0 gives 'Discrete(6)' as output, i.e.0,1,2,3,4,5 are actions defined in environment as per documentation, but game needs only two controls. Why this discrepency? Further is that necessary to identify which number from 0 to 5 corresponds to which action in gym environment?</p><br>""",ai
